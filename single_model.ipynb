{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b5d7f8",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32529efc",
   "metadata": {},
   "source": [
    "## token-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b821a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Random Forest on Token2Vec Results:\n",
      "Precision     : 0.9949\n",
      "Recall        : 0.9947\n",
      "F1-score      : 0.9948\n",
      "Accuracy      : 0.9921\n",
      "Detection Time: 1.11 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class → numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"📊 Random Forest on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad71cd",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e6ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Random Forest on Char2Vec Results:\n",
      "Precision     : 0.9877\n",
      "Recall        : 0.9878\n",
      "F1-score      : 0.9876\n",
      "Accuracy      : 0.9815\n",
      "Detection Time: 2.46 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class → numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"📊 Random Forest on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effeb252",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20a9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Random Forest on Ast2Vec Results:\n",
      "Precision     : 0.9856\n",
      "Recall        : 0.9862\n",
      "F1-score      : 0.9855\n",
      "Accuracy      : 0.9788\n",
      "Detection Time: 2.60 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class → numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"📊 Random Forest on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946fe2d",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fc805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Random Forest on Rela2Vec Results:\n",
      "Precision     : 0.5102\n",
      "Recall        : 0.5131\n",
      "F1-score      : 0.5109\n",
      "Accuracy      : 0.8598\n",
      "Detection Time: 4.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class → numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"📊 Random Forest on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911627e",
   "metadata": {},
   "source": [
    "# cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff032641",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a632272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "📊 CNN on Token2Vec Results:\n",
      "Precision     : 0.9902\n",
      "Recall        : 0.9426\n",
      "F1-score      : 0.9627\n",
      "Accuracy      : 0.9854\n",
      "Detection Time: 24.93 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_cat = lb.fit_transform(y_text)   # for Keras\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "# ===== Compile =====\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Print results =====\n",
    "print(\"📊 CNN on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187115d",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f9bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "📊 CNN on Char2Vec Results:\n",
      "Precision     : 0.7199\n",
      "Recall        : 0.7217\n",
      "F1-score      : 0.7206\n",
      "Accuracy      : 0.8823\n",
      "Detection Time: 23.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_cat = lb.fit_transform(y_text) \n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "# ===== Compile =====\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Print results =====\n",
    "print(\"📊 CNN on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752a5fb",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d60c76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "📊 CNN on Ast2Vec Results:\n",
      "Precision     : 0.7376\n",
      "Recall        : 0.6881\n",
      "F1-score      : 0.7085\n",
      "Accuracy      : 0.9061\n",
      "Detection Time: 22.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)  # one-hot labels\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 CNN on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0b7bc",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55bf2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "📊 CNN on Rela2Vec Results:\n",
      "Precision     : 0.5231\n",
      "Recall        : 0.5292\n",
      "F1-score      : 0.5255\n",
      "Accuracy      : 0.8796\n",
      "Detection Time: 21.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 CNN on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f4d09",
   "metadata": {},
   "source": [
    "# bilstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cd333",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "750e7225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "📊 BiLSTM on Token2Vec Results:\n",
      "Precision     : 0.5715\n",
      "Recall        : 0.5743\n",
      "F1-score      : 0.5422\n",
      "Accuracy      : 0.8161\n",
      "Detection Time: 54.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiLSTM on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f8db4",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093b9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "📊 BiLSTM on Char2Vec Results:\n",
      "Precision     : 0.5052\n",
      "Recall        : 0.4772\n",
      "F1-score      : 0.4667\n",
      "Accuracy      : 0.8161\n",
      "Detection Time: 55.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM expects 3D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiLSTM on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c4dfd",
   "metadata": {},
   "source": [
    "# ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122073d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "📊 BiLSTM on Ast2Vec Results:\n",
      "Precision     : 0.7227\n",
      "Recall        : 0.6346\n",
      "F1-score      : 0.6610\n",
      "Accuracy      : 0.8664\n",
      "Detection Time: 53.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiLSTM on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1ebf7",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9163a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "📊 BiLSTM on Rela2Vec Results:\n",
      "Precision     : 0.4550\n",
      "Recall        : 0.4490\n",
      "F1-score      : 0.4348\n",
      "Accuracy      : 0.7659\n",
      "Detection Time: 54.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM expects shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiLSTM on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1094f4",
   "metadata": {},
   "source": [
    "# bigru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969850ae",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fab292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "📊 BiGRU on Token2Vec Results:\n",
      "Precision     : 0.6409\n",
      "Recall        : 0.6503\n",
      "F1-score      : 0.6446\n",
      "Accuracy      : 0.9206\n",
      "Detection Time: 65.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiGRU input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiGRU on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1295dac",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a32628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "📊 BiGRU on Char2Vec Results:\n",
      "Precision     : 0.5026\n",
      "Recall        : 0.4848\n",
      "F1-score      : 0.4783\n",
      "Accuracy      : 0.8254\n",
      "Detection Time: 64.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # GRU expects shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiGRU on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b58a36",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb07283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
      "📊 BiGRU on Ast2Vec Results:\n",
      "Precision     : 0.5142\n",
      "Recall        : 0.5216\n",
      "F1-score      : 0.5176\n",
      "Accuracy      : 0.8704\n",
      "Detection Time: 67.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Input shape for BiGRU: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiGRU on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2eab7",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c65137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "📊 BiGRU on Rela2Vec Results:\n",
      "Precision     : 0.4885\n",
      "Recall        : 0.4939\n",
      "F1-score      : 0.4884\n",
      "Accuracy      : 0.8267\n",
      "Detection Time: 65.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # GRU expects input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 BiGRU on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5c67b",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bcb3d",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a691a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "📊 Transformer on Token2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 15.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Parse Token2Vec =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer expects 3D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Define Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(Add()([inputs, attn_output]))\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(Add()([out1, ff_output]))\n",
    "    return out2\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 Transformer on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c2e68",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a75aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "📊 Transformer on Char2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 16.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # shape for Transformer: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer encoder block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 Transformer on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc3d51",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a42f50f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "📊 Transformer on Ast2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 17.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer expects (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 Transformer on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c39d9",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6742208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "📊 Transformer on Rela2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 16.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"📊 Transformer on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47b6f7",
   "metadata": {},
   "source": [
    "# CNN-BiLSTM+ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c4ff2",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0205ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "📊 CNN-BiLSTM+Attention on Token2Vec:\n",
      "Precision     : 0.5433\n",
      "Recall        : 0.5341\n",
      "F1-score      : 0.5346\n",
      "Accuracy      : 0.8942\n",
      "Detection Time: 36.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer, Flatten\n",
    "from tensorflow.keras.layers import Attention, Permute, Multiply, Softmax, Lambda, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # input shape for CNN + BiLSTM\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Train/Test split =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===== Define Attention Layer =====\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "\n",
    "# CNN\n",
    "x = Conv1D(filters=128, kernel_size=5, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "# BiLSTM\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "# Attention\n",
    "x = AttentionLayer()(x)\n",
    "\n",
    "# Output layers\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output =====\n",
    "print(\"📊 CNN-BiLSTM+Attention on Token2Vec:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281b889",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ecd613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "📊 CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.5315\n",
      "Recall        : 0.5330\n",
      "F1-score      : 0.5291\n",
      "Accuracy      : 0.8862\n",
      "Detection Time: 37.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"📊 CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4f1a7",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "979427c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "📊 CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.5178\n",
      "Recall        : 0.5249\n",
      "F1-score      : 0.5213\n",
      "Accuracy      : 0.8770\n",
      "Detection Time: 36.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"📊 CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2aa5a3",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4f81e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "📊 CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.4086\n",
      "Recall        : 0.4062\n",
      "F1-score      : 0.3558\n",
      "Accuracy      : 0.7156\n",
      "Detection Time: 36.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"📊 CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
