{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b5d7f8",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32529efc",
   "metadata": {},
   "source": [
    "## token-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b821a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Random Forest on Token2Vec Results:\n",
      "Precision     : 0.9949\n",
      "Recall        : 0.9947\n",
      "F1-score      : 0.9948\n",
      "Accuracy      : 0.9921\n",
      "Detection Time: 1.11 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class ‚Üí numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"üìä Random Forest on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad71cd",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e6ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Random Forest on Char2Vec Results:\n",
      "Precision     : 0.9877\n",
      "Recall        : 0.9878\n",
      "F1-score      : 0.9876\n",
      "Accuracy      : 0.9815\n",
      "Detection Time: 2.46 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class ‚Üí numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"üìä Random Forest on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effeb252",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20a9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Random Forest on Ast2Vec Results:\n",
      "Precision     : 0.9856\n",
      "Recall        : 0.9862\n",
      "F1-score      : 0.9855\n",
      "Accuracy      : 0.9788\n",
      "Detection Time: 2.60 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class ‚Üí numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"üìä Random Forest on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946fe2d",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fc805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Random Forest on Rela2Vec Results:\n",
      "Precision     : 0.5102\n",
      "Recall        : 0.5131\n",
      "F1-score      : 0.5109\n",
      "Accuracy      : 0.8598\n",
      "Detection Time: 4.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "y_text = df['Label']\n",
    "\n",
    "# One-hot encode labels (multi-class ‚Üí numeric labels)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_labels = np.argmax(y, axis=1)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_labels, test_size=0.2, stratify=y_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Train RandomForestClassifier =====\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Predict and Evaluate =====\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ===== Display Results =====\n",
    "print(\"üìä Random Forest on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911627e",
   "metadata": {},
   "source": [
    "# cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff032641",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a632272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "üìä CNN on Token2Vec Results:\n",
      "Precision     : 0.9902\n",
      "Recall        : 0.9426\n",
      "F1-score      : 0.9627\n",
      "Accuracy      : 0.9854\n",
      "Detection Time: 24.93 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_cat = lb.fit_transform(y_text)   # for Keras\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "# ===== Compile =====\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Print results =====\n",
    "print(\"üìä CNN on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187115d",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f9bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "üìä CNN on Char2Vec Results:\n",
      "Precision     : 0.7199\n",
      "Recall        : 0.7217\n",
      "F1-score      : 0.7206\n",
      "Accuracy      : 0.8823\n",
      "Detection Time: 23.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "y_cat = lb.fit_transform(y_text) \n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "# ===== Compile =====\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Print results =====\n",
    "print(\"üìä CNN on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752a5fb",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d60c76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "üìä CNN on Ast2Vec Results:\n",
      "Precision     : 0.7376\n",
      "Recall        : 0.6881\n",
      "F1-score      : 0.7085\n",
      "Accuracy      : 0.9061\n",
      "Detection Time: 22.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)  # one-hot labels\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä CNN on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0b7bc",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55bf2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "üìä CNN on Rela2Vec Results:\n",
      "Precision     : 0.5231\n",
      "Recall        : 0.5292\n",
      "F1-score      : 0.5255\n",
      "Accuracy      : 0.8796\n",
      "Detection Time: 21.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # reshape for Conv1D\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build CNN model =====\n",
    "model = Sequential([\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä CNN on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f4d09",
   "metadata": {},
   "source": [
    "# bilstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cd333",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "750e7225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "üìä BiLSTM on Token2Vec Results:\n",
      "Precision     : 0.5715\n",
      "Recall        : 0.5743\n",
      "F1-score      : 0.5422\n",
      "Accuracy      : 0.8161\n",
      "Detection Time: 54.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiLSTM on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f8db4",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093b9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "üìä BiLSTM on Char2Vec Results:\n",
      "Precision     : 0.5052\n",
      "Recall        : 0.4772\n",
      "F1-score      : 0.4667\n",
      "Accuracy      : 0.8161\n",
      "Detection Time: 55.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM expects 3D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiLSTM on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c4dfd",
   "metadata": {},
   "source": [
    "# ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122073d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "üìä BiLSTM on Ast2Vec Results:\n",
      "Precision     : 0.7227\n",
      "Recall        : 0.6346\n",
      "F1-score      : 0.6610\n",
      "Accuracy      : 0.8664\n",
      "Detection Time: 53.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiLSTM on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1ebf7",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9163a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "üìä BiLSTM on Rela2Vec Results:\n",
      "Precision     : 0.4550\n",
      "Recall        : 0.4490\n",
      "F1-score      : 0.4348\n",
      "Accuracy      : 0.7659\n",
      "Detection Time: 54.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiLSTM expects shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiLSTM model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiLSTM on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1094f4",
   "metadata": {},
   "source": [
    "# bigru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969850ae",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fab292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "üìä BiGRU on Token2Vec Results:\n",
      "Precision     : 0.6409\n",
      "Recall        : 0.6503\n",
      "F1-score      : 0.6446\n",
      "Accuracy      : 0.9206\n",
      "Detection Time: 65.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Token2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # BiGRU input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiGRU on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1295dac",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a32628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "üìä BiGRU on Char2Vec Results:\n",
      "Precision     : 0.5026\n",
      "Recall        : 0.4848\n",
      "F1-score      : 0.4783\n",
      "Accuracy      : 0.8254\n",
      "Detection Time: 64.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # GRU expects shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiGRU on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b58a36",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb07283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
      "üìä BiGRU on Ast2Vec Results:\n",
      "Precision     : 0.5142\n",
      "Recall        : 0.5216\n",
      "F1-score      : 0.5176\n",
      "Accuracy      : 0.8704\n",
      "Detection Time: 67.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Input shape for BiGRU: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiGRU on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2eab7",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c65137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "üìä BiGRU on Rela2Vec Results:\n",
      "Precision     : 0.4885\n",
      "Recall        : 0.4939\n",
      "F1-score      : 0.4884\n",
      "Accuracy      : 0.8267\n",
      "Detection Time: 65.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # GRU expects input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Build BiGRU model =====\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=False), input_shape=(X.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä BiGRU on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5c67b",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bcb3d",
   "metadata": {},
   "source": [
    "## token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a691a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "üìä Transformer on Token2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 15.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Parse Token2Vec =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer expects 3D input\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Define Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(Add()([inputs, attn_output]))\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(Add()([out1, ff_output]))\n",
    "    return out2\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä Transformer on Token2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c2e68",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a75aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "üìä Transformer on Char2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 16.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Char2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # shape for Transformer: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer encoder block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä Transformer on Char2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc3d51",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a42f50f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "üìä Transformer on Ast2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 17.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled_raw.csv')\n",
    "\n",
    "# ===== Convert Ast2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer expects (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä Transformer on Ast2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c39d9",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6742208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "üìä Transformer on Rela2Vec Results:\n",
      "Precision     : 0.0802\n",
      "Recall        : 0.2000\n",
      "F1-score      : 0.1144\n",
      "Accuracy      : 0.4008\n",
      "Detection Time: 16.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Rela2Vec column to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # Transformer input shape: (samples, timesteps, features)\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Split train/test =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ===== Transformer Encoder Block =====\n",
    "def transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = Add()([inputs, attn_output])\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(inputs.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    out2 = Add()([out1, ff_output])\n",
    "    return LayerNormalization(epsilon=1e-6)(out2)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "x = transformer_encoder(input_layer, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output Results =====\n",
    "print(\"üìä Transformer on Rela2Vec Results:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47b6f7",
   "metadata": {},
   "source": [
    "# CNN-BiLSTM+ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c4ff2",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0205ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "üìä CNN-BiLSTM+Attention on Token2Vec:\n",
      "Precision     : 0.5433\n",
      "Recall        : 0.5341\n",
      "F1-score      : 0.5346\n",
      "Accuracy      : 0.8942\n",
      "Detection Time: 36.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer, Flatten\n",
    "from tensorflow.keras.layers import Attention, Permute, Multiply, Softmax, Lambda, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "# ===== Convert Token2Vec to numpy array =====\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['token_vector'] = parse_vector_column('Token2Vec')\n",
    "\n",
    "# ===== Prepare X and y =====\n",
    "X = np.stack(df['token_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # input shape for CNN + BiLSTM\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "# ===== Train/Test split =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===== Define Attention Layer =====\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "# ===== Build Model =====\n",
    "input_layer = Input(shape=(X.shape[1], 1))\n",
    "\n",
    "# CNN\n",
    "x = Conv1D(filters=128, kernel_size=5, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "# BiLSTM\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "# Attention\n",
    "x = AttentionLayer()(x)\n",
    "\n",
    "# Output layers\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ===== Train =====\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "# ===== Evaluate =====\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "precision = np.mean([report[label]['precision'] for label in lb.classes_])\n",
    "recall = np.mean([report[label]['recall'] for label in lb.classes_])\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# ===== Output =====\n",
    "print(\"üìä CNN-BiLSTM+Attention on Token2Vec:\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281b889",
   "metadata": {},
   "source": [
    "## character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ecd613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "üìä CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.5315\n",
      "Recall        : 0.5330\n",
      "F1-score      : 0.5291\n",
      "Accuracy      : 0.8862\n",
      "Detection Time: 37.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['char_vector'] = parse_vector_column('Char2Vec')\n",
    "X = np.stack(df['char_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"üìä CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4f1a7",
   "metadata": {},
   "source": [
    "## ast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "979427c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "üìä CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.5178\n",
      "Recall        : 0.5249\n",
      "F1-score      : 0.5213\n",
      "Accuracy      : 0.8770\n",
      "Detection Time: 36.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['ast_vector'] = parse_vector_column('Ast2Vec')\n",
    "X = np.stack(df['ast_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"üìä CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2aa5a3",
   "metadata": {},
   "source": [
    "## rela level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4f81e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "üìä CNN-BiLSTM+ATT on Char2Vec\n",
      "Precision     : 0.4086\n",
      "Recall        : 0.4062\n",
      "F1-score      : 0.3558\n",
      "Accuracy      : 0.7156\n",
      "Detection Time: 36.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ubuntu/powershell_detection_multimodel_multioutput/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ===== Load dataset =====\n",
    "df = pd.read_csv('./dataset/data_labeled.csv')\n",
    "\n",
    "def parse_vector_column(col):\n",
    "    return df[col].apply(lambda x: np.array([float(i) for i in str(x).strip().split()]))\n",
    "\n",
    "df['rela_vector'] = parse_vector_column('Rela2Vec')\n",
    "X = np.stack(df['rela_vector'].values)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "y_text = df['Label']\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
    "        self.b = self.add_weight(shape=(input_shape[1], 1), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "inp = Input(shape=(X.shape[1], 1))\n",
    "x = Conv1D(128, 5, activation='relu')(inp)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = AttentionLayer()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "out = Dense(y.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "detection_time = time.time() - start_time\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=lb.classes_, output_dict=True)\n",
    "print(\"üìä CNN-BiLSTM+ATT on Char2Vec\")\n",
    "print(f\"Precision     : {np.mean([report[l]['precision'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"Recall        : {np.mean([report[l]['recall'] for l in lb.classes_]):.4f}\")\n",
    "print(f\"F1-score      : {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "print(f\"Accuracy      : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Detection Time: {detection_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
