{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t4nti3n/powershell_detection_multimodel_multioutput/blob/gan/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyMyfUbGP_oR"
      },
      "source": [
        "#GAN#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e4ZwgWDZpbi"
      },
      "source": [
        "## [1]: Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJaLOqu89v5l"
      },
      "source": [
        "### load and view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2bXVTl-Piel",
        "outputId": "eead752c-3de2-41a0-ce75-23f74f6b06af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n",
            "                                        Full Payload       Label  \\\n",
            "0  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
            "1  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....  Downloader   \n",
            "2  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
            "3  powershell.exe -nop -wind hidden -Exec Bypass ...     Payload   \n",
            "4  powershell -window hidden -enc $1 = '$c = ''[D...    Injector   \n",
            "\n",
            "                                        FusionVector  \n",
            "0  -0.18999852 -0.48553216 -0.87083316 0.2666215 ...  \n",
            "1  -0.3947524 0.010655806 -0.67612636 -0.07839656...  \n",
            "2  -0.1899367 -0.5148512 -0.90198445 0.2528152 -0...  \n",
            "3  -0.17432946 0.028123861 -0.5588947 -0.03192398...  \n",
            "4  -0.24262634 -0.5209265 -0.8235193 0.15971158 -...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = './dataset/fusion_with_vector_extended.csv'\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(file_path)\n",
        "  print(\"Dataset loaded successfully.\")\n",
        "  print(df.head())\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found at {file_path}. Please check the file path.\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qCbT8oKQToe1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"./GAN/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "output_file = os.path.join(output_dir, \"sample_fushion.csv\")\n",
        "\n",
        "df.head().to_csv(output_file, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFS6FTLEZzhH"
      },
      "source": [
        "## [2]: Defined Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gotF-Sgr2lz",
        "outputId": "566e499f-f58a-4018-b29b-dfe340077527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Invalid labels found in batch: tensor([[5]])\n",
            "Warning: Invalid labels found in batch: tensor([[5]])\n",
            "Epoch 10/50, Average Loss: 0.1411\n",
            "Epoch 20/50, Average Loss: 0.0823\n",
            "Epoch 30/50, Average Loss: 0.0552\n",
            "Epoch 40/50, Average Loss: 0.0467\n",
            "Epoch 50/50, Average Loss: 0.0364\n",
            "Discriminator Test Accuracy: 0.9746\n",
            "Discriminator model saved as 'discriminator_model.pth'\n",
            "Scaler and label encoder saved\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, feature_dim=512):\n",
        "    # Load CSV\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Parse FusionVector (space-separated string to array)\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "\n",
        "    # Validate feature dimension\n",
        "    assert features.shape[1] == feature_dim, f\"Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    return features, labels, scaler, label_encoder\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):  # Assuming 5 classes based on the error\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)  # Output layer for num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Train and evaluate discriminator\n",
        "def train_discriminator(discriminator, features, labels, test_size=0.2, epochs=50, batch_size=64, lr=0.0002):\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=test_size, stratify=labels, random_state=42\n",
        "    )\n",
        "\n",
        "    # Optimizer and loss\n",
        "    optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    class_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    discriminator.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0  # To accumulate loss for the epoch\n",
        "        num_batches = 0  # To count batches for averaging loss\n",
        "\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_features = X_train[i:i+batch_size]\n",
        "            batch_labels = y_train[i:i+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = discriminator(batch_features)\n",
        "\n",
        "            # Check if any label is out of bounds and adjust if necessary\n",
        "            # This step handles potential issues with the dataset\n",
        "            invalid_labels = (batch_labels >= discriminator.model[-1].out_features).nonzero()\n",
        "            if invalid_labels.nelement() > 0:\n",
        "                # Print or handle invalid labels (e.g., replace with max valid label)\n",
        "                print(f\"Warning: Invalid labels found in batch: {batch_labels[invalid_labels]}\")\n",
        "                batch_labels[invalid_labels] = discriminator.model[-1].out_features - 1\n",
        "\n",
        "            loss = class_loss(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()  # Accumulate loss\n",
        "            num_batches += 1  # Increment batch count\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / num_batches  # Calculate average loss\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    discriminator.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = discriminator(X_test)\n",
        "        test_preds = torch.argmax(test_outputs, dim=1)\n",
        "        accuracy = accuracy_score(y_test.numpy(), test_preds.numpy())\n",
        "\n",
        "    print(f\"Discriminator Test Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy, X_train, y_train, X_test, y_test, scaler, label_encoder\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    feature_dim = 512  # From dataset\n",
        "    batch_size = 64\n",
        "    epochs = 50\n",
        "    accuracy_threshold = 0.7  # Adjust as needed\n",
        "\n",
        "    # Load dataset (replace with your CSV path)\n",
        "    csv_path = \"./dataset/fusion_with_vector_extended.csv\"  # Placeholder\n",
        "    features, labels, scaler, label_encoder = load_and_preprocess_data(csv_path, feature_dim)\n",
        "\n",
        "    # Initialize discriminator\n",
        "    discriminator = Discriminator(feature_dim)\n",
        "\n",
        "    # Train and evaluate\n",
        "    accuracy, X_train, y_train, X_test, y_test, scaler, label_encoder = train_discriminator(\n",
        "        discriminator, features, labels, epochs=epochs, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Save model if satisfactory\n",
        "    if accuracy >= accuracy_threshold:\n",
        "        torch.save(discriminator.state_dict(), \"./GAN/discriminator_model.pth\")\n",
        "        print(\"Discriminator model saved as 'discriminator_model.pth'\")\n",
        "        # Save scaler and label encoder for GAN\n",
        "        np.save(\"./GAN/scaler_params.npy\", [scaler.mean_, scaler.scale_])\n",
        "        np.save(\"./GAN/label_encoder_classes.npy\", label_encoder.classes_)\n",
        "        print(\"Scaler and label encoder saved\")\n",
        "    else:\n",
        "        print(\"Discriminator accuracy below threshold. Adjust model or hyperparameters.\")\n",
        "\n",
        "#The code below was improperly indented and is now moved to within the main execution block.\n",
        "#It has also been edited to provide more information about invalid labels if they are found.\n",
        "    # Check for invalid labels after training\n",
        "    # This step can now use label_encoder which is defined in this scope.\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_features = X_train[i : i + batch_size]\n",
        "        batch_labels = y_train[i : i + batch_size]\n",
        "        invalid_labels = (batch_labels >= discriminator.model[-1].out_features).nonzero()\n",
        "        if invalid_labels.nelement() > 0:\n",
        "            for idx in invalid_labels:\n",
        "                invalid_label_value = batch_labels[idx].item()\n",
        "                print(f\"Warning: Invalid label found: {invalid_label_value}.  \"\n",
        "                      f\"Original Label: {label_encoder.inverse_transform([invalid_label_value])}, \"\n",
        "                      f\"Max valid label: {discriminator.model[-1].out_features - 1}\")\n",
        "            batch_labels[invalid_labels] = discriminator.model[-1].out_features - 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w_vLVO2e-WB",
        "outputId": "89126acc-20fc-4fb9-ee75-47e3bb72ecbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original labels for the first 10 data points in the test set:\n",
            "Data point 1: Original Label = Injector, Encoded Label = 2\n",
            "Data point 2: Original Label = Injector, Encoded Label = 2\n",
            "Data point 3: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 4: Original Label = Bypass, Encoded Label = 0\n",
            "Data point 5: Original Label = Payload, Encoded Label = 3\n",
            "Data point 6: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 7: Original Label = Payload, Encoded Label = 3\n",
            "Data point 8: Original Label = TaskExecution, Encoded Label = 4\n",
            "Data point 9: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 10: Original Label = TaskExecution, Encoded Label = 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the saved scaler and label encoder\n",
        "scaler_params = np.load(\"./GAN/scaler_params.npy\", allow_pickle=True)\n",
        "label_encoder_classes = np.load(\"./GAN/label_encoder_classes.npy\", allow_pickle=True)\n",
        "\n",
        "# Recreate the scaler and label encoder\n",
        "scaler = StandardScaler()\n",
        "scaler.mean_ = scaler_params[0]\n",
        "scaler.scale_ = scaler_params[1]\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = label_encoder_classes\n",
        "\n",
        "# Example: Show original labels for the first 10 data points in the test set\n",
        "print(\"Original labels for the first 10 data points in the test set:\")\n",
        "for i in range(10):  # Adjust range as needed\n",
        "        original_label = label_encoder.inverse_transform([y_test[i].item()])[0]\n",
        "        print(f\"Data point {i+1}: Original Label = {original_label}, Encoded Label = {y_test[i].item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHKtwuFGZ7sM"
      },
      "source": [
        "## [3]: Gen Noising Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxH-d31EzGV0"
      },
      "source": [
        "### Load discriminotr and Gen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3CrIpFb5BAE",
        "outputId": "b5b50193-aabe-4be5-ae2f-55ffabac1ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 3 rows with invalid labels.\n",
            "Unique labels after filtering: ['Injector' 'Downloader' 'Payload' 'TaskExecution' 'Bypass']\n",
            "All unique labels: ['Bypass' 'Downloader' 'Injector' 'Payload' 'TaskExecution']\n",
            "Number of unique labels: 5\n",
            "\n",
            "Original and encoded labels for the first 10 data points:\n",
            "Data point 1: Original Label = Injector, Encoded Label = 2\n",
            "Data point 2: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 3: Original Label = Injector, Encoded Label = 2\n",
            "Data point 4: Original Label = Payload, Encoded Label = 3\n",
            "Data point 5: Original Label = Injector, Encoded Label = 2\n",
            "Data point 6: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 7: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 8: Original Label = Injector, Encoded Label = 2\n",
            "Data point 9: Original Label = Downloader, Encoded Label = 1\n",
            "Data point 10: Original Label = Downloader, Encoded Label = 1\n",
            "Discriminator model loaded successfully.\n",
            "Epoch 10/200, Generator Loss: 1.6183\n",
            "Epoch 20/200, Generator Loss: 1.6158\n",
            "Epoch 30/200, Generator Loss: 1.6160\n",
            "Epoch 40/200, Generator Loss: 1.6142\n",
            "Epoch 50/200, Generator Loss: 1.6159\n",
            "Epoch 60/200, Generator Loss: 1.6152\n",
            "Epoch 70/200, Generator Loss: 1.6141\n",
            "Epoch 80/200, Generator Loss: 1.6143\n",
            "Epoch 90/200, Generator Loss: 1.6143\n",
            "Epoch 100/200, Generator Loss: 1.6126\n",
            "Epoch 110/200, Generator Loss: 1.6138\n",
            "Epoch 120/200, Generator Loss: 1.6130\n",
            "Epoch 130/200, Generator Loss: 1.6119\n",
            "Epoch 140/200, Generator Loss: 1.6125\n",
            "Epoch 150/200, Generator Loss: 1.6116\n",
            "Epoch 160/200, Generator Loss: 1.6114\n",
            "Epoch 170/200, Generator Loss: 1.6113\n",
            "Epoch 180/200, Generator Loss: 1.6111\n",
            "Epoch 190/200, Generator Loss: 1.6105\n",
            "Epoch 200/200, Generator Loss: 1.6109\n",
            "Synthetic dataset saved as './GAN/synthetic_powershell_malware.csv'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Display labels and encodings\n",
        "def display_labels(data, num_samples=10):\n",
        "    valid_labels = {'Bypass', 'Downloader', 'Injector', 'Payload', 'TaskExecution'}\n",
        "    data = data[data['Label'].isin(valid_labels)]\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "    unique_labels = label_encoder.classes_\n",
        "    print(f\"All unique labels: {unique_labels}\")\n",
        "    print(f\"Number of unique labels: {len(unique_labels)}\")\n",
        "\n",
        "    print(f\"\\nOriginal and encoded labels for the first {min(num_samples, len(data))} data points:\")\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        print(f\"Data point {i+1}: Original Label = {data['Label'].iloc[i]}, Encoded Label = {encoded_labels[i]}\")\n",
        "\n",
        "    return label_encoder.classes_\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, scaler_params, feature_dim=512):\n",
        "    data = pd.read_csv(csv_path)\n",
        "    valid_labels = {'Bypass', 'Downloader', 'Injector', 'Payload', 'TaskExecution'}\n",
        "\n",
        "    original_rows = len(data)\n",
        "    data = data[data['Label'].isin(valid_labels)]\n",
        "    removed_rows = original_rows - len(data)\n",
        "    if removed_rows > 0:\n",
        "        print(f\"Removed {removed_rows} rows with invalid labels.\")\n",
        "    else:\n",
        "        print(\"No rows with invalid labels found.\")\n",
        "\n",
        "    if data.empty:\n",
        "        raise ValueError(\"No rows remain after filtering. Check dataset labels.\")\n",
        "\n",
        "    unique_labels = data['Label'].unique()\n",
        "    print(f\"Unique labels after filtering: {unique_labels}\")\n",
        "\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "    assert features.shape[1] == feature_dim, f\"Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.mean_, scaler.scale_ = scaler_params[0], scaler_params[1]\n",
        "    features = scaler.transform(features)\n",
        "\n",
        "    features = torch.FloatTensor(features)\n",
        "    return features, data, scaler\n",
        "\n",
        "# Discriminator Model (Matches training script)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        noise = torch.randn_like(x) * 0.05\n",
        "        return self.model(x + noise)\n",
        "\n",
        "# Train GAN\n",
        "def train_gan(discriminator, generator, features, noise_dim=100, epochs=200, batch_size=64, lr=0.0002):\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    class_loss = nn.CrossEntropyLoss()  # Use classification loss since discriminator is a classifier\n",
        "\n",
        "    discriminator.eval()\n",
        "    for param in discriminator.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    generator.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_g_loss = 0\n",
        "        for i in range(0, len(features), batch_size):\n",
        "            real_data = features[i:i+batch_size]\n",
        "            batch_size_actual = real_data.size(0)\n",
        "\n",
        "            noise = torch.randn(batch_size_actual, noise_dim)\n",
        "            fake_data = generator(noise)\n",
        "            # Generate random labels for fake data (simulating classification)\n",
        "            fake_labels = torch.randint(0, discriminator.model[-1].out_features, (batch_size_actual,))\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            g_outputs = discriminator(fake_data)\n",
        "            g_loss = class_loss(g_outputs, fake_labels)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "            total_g_loss += g_loss.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_g_loss = total_g_loss / (len(features) // batch_size + 1)\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Generator Loss: {avg_g_loss:.4f}\")\n",
        "\n",
        "    return generator\n",
        "\n",
        "# Generate synthetic dataset\n",
        "def generate_synthetic_dataset(generator, num_samples, noise_dim, scaler, label_encoder_classes, input_data, copy_payload=False):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(num_samples, noise_dim)\n",
        "        synthetic_data = generator(noise).numpy()\n",
        "\n",
        "    synthetic_data = scaler.inverse_transform(synthetic_data)\n",
        "    synthetic_labels = np.random.choice(label_encoder_classes, size=num_samples)\n",
        "\n",
        "    if copy_payload:\n",
        "        payload_values = input_data['Full Payload'].dropna().sample(num_samples, replace=True).values\n",
        "    else:\n",
        "        payload_values = [''] * num_samples\n",
        "\n",
        "    synthetic_df = pd.DataFrame({\n",
        "        'Full Payload': payload_values,\n",
        "        'Label': synthetic_labels,\n",
        "        'FusionVector': [' '.join(map(str, vec)) for vec in synthetic_data]\n",
        "    })\n",
        "\n",
        "    return synthetic_df\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    feature_dim = 512\n",
        "    noise_dim = 100\n",
        "    batch_size = 64\n",
        "    epochs = 200\n",
        "    num_classes = 5\n",
        "    copy_payload = False\n",
        "\n",
        "    # Load dataset and scaler\n",
        "    csv_path = \"./dataset/fusion_with_vector_extended.csv\"\n",
        "    try:\n",
        "        scaler_params = np.load(\"./GAN/scaler_params.npy\", allow_pickle=True)\n",
        "        features, original_data, scaler = load_and_preprocess_data(csv_path, scaler_params, feature_dim)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset or scaler: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Display labels\n",
        "    try:\n",
        "        label_encoder_classes = display_labels(original_data)\n",
        "        if len(label_encoder_classes) != num_classes:\n",
        "            print(f\"Warning: Expected {num_classes} labels, found {len(label_encoder_classes)}. Updating num_classes.\")\n",
        "            num_classes = len(label_encoder_classes)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing labels: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Load discriminator\n",
        "    try:\n",
        "        discriminator = Discriminator(feature_dim, num_classes)\n",
        "        saved_state_dict = torch.load(\"./GAN/discriminator_model.pth\")\n",
        "        # Rename keys to match 'model' prefix\n",
        "        model_state_dict = {k.replace('model.', ''): v for k, v in saved_state_dict.items()}\n",
        "        discriminator.model.load_state_dict(model_state_dict)\n",
        "        print(\"Discriminator model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading discriminator model: {e}\")\n",
        "        print(\"Proceeding without loading saved discriminator weights.\")\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = Generator(noise_dim, feature_dim)\n",
        "\n",
        "    # Train GAN\n",
        "    try:\n",
        "        generator = train_gan(discriminator, generator, features, noise_dim=noise_dim, epochs=epochs, batch_size=batch_size)\n",
        "    except Exception as e:\n",
        "        print(f\"Error training GAN: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Generate synthetic dataset\n",
        "    try:\n",
        "        synthetic_df = generate_synthetic_dataset(\n",
        "            generator, len(original_data), noise_dim, scaler, label_encoder_classes, original_data, copy_payload=copy_payload\n",
        "        )\n",
        "        synthetic_df.to_csv(\"./GAN/synthetic_powershell_malware.csv\", index=False, na_rep='')\n",
        "        print(\"Synthetic dataset saved as './GAN/synthetic_powershell_malware.csv'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating synthetic dataset: {e}\")\n",
        "        exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9mmQmYfQXHh"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHTdsvR6bNdn"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2uZn5zhaldl"
      },
      "source": [
        "## Test concept:\n",
        "Context Recap\n",
        "- Datasets:\n",
        "A (Original): powershell_malware.csv, contains Full Payload (ignored), Label (5 classes: Bypass, Downloader, Injector, Payload, TaskExecution), and FusionVector (512 numerical features).\n",
        "B (Synthetic): synthetic_powershell_malware.csv, generated by the GAN to bypass the discriminator, same format but with noisy FusionVector features.\n",
        "- Models:\n",
        "M1 (Fusion Model): Your provided TensorFlow model combining CNN, BiLSTM, Multi-Head Attention, and Dense layers, extended to handle 512 features (input shape (512, 1)).\n",
        "M2 (Mono Model): Not specified, but I’ll assume a simpler model (e.g., a Multi-Layer Perceptron or single CNN) for contrast, also handling 512 features.\n",
        "- Objective:\n",
        "Compare M1 and M2 to highlight M1’s strengths (e.g., robustness to noise due to fusion of CNN, LSTM, and Transformer).\n",
        "Assess their ability to handle noisy data (B) that aims to confuse the discriminator.\n",
        "### aproach 1\n",
        "Train M1 and M2 on A, Test on B\n",
        "Process:\n",
        " - Train M1 on Dataset A’s training set.\n",
        " -  Train M2 on Dataset A’s training set.\n",
        " - Test both models on Dataset B’s test set.\n",
        " - Record accuracy for M1 and M2 on B.\n",
        " - Compare accuracies to evaluate which model better handles noisy data.\n",
        "Evaluation Metric: Accuracy on B (possibly supplemented with loss or F1-score).\n",
        "\n",
        "Prop and cons:\n",
        "- Pros: Simplicity: Straightforward to implement and interpret. Only one training phase per model.\n",
        "Direct Noise Evaluation: Tests how well each model generalizes to noisy synthetic data (B) after learning from clean data (A), directly assessing robustness to the GAN’s perturbations.\n",
        "Realistic Scenario: Mimics real-world use where models are trained on clean data but must handle noisy or adversarial inputs during deployment.\n",
        "Low Computational Cost: Requires training each model once, making it efficient.\n",
        "- Cons: Limited Insight into Baseline Performance: Doesn’t evaluate performance on A, so we can’t compare how well the models perform on clean data or how much performance drops due to noise.\n",
        "Noisy Data Bias: If B’s labels are random or poorly aligned with A’s distribution (due to GAN’s random label assignment), accuracy on B may be misleading (e.g., both models perform poorly due to label noise rather than feature noise).\n",
        "No Intra-Dataset Comparison: Doesn’t show how models perform on their training distribution (A), which is critical for understanding M1’s fusion benefits.\n",
        "\n",
        "### aproach 2:\n",
        "Train and Test M1/M2 on A and B, Compare Performance Decrease\n",
        "Process:\n",
        " - Train M1 on A, test on A, record accuracy/loss (R1).\n",
        " - Train M2 on A, test on A, record accuracy/loss (R2).\n",
        " - Train M1 on B, test on B, record accuracy/loss (R1').\n",
        " - Train M2 on B, test on B, record accuracy/loss (R2').\n",
        " - Compute performance decrease:\n",
        "  -+ For M1: (R1 - R1') / R1 (percentage drop).\n",
        "  -+ For M2: (R2 - R2') / R2 (percentage drop).\n",
        " - Compare the percentage drops to evaluate which model is more robust to noisy data.\n",
        "Evaluation Metric: Percentage decrease in accuracy (or increase in loss) from A to B.\n",
        "\n",
        "Prop and cons:\n",
        "- Pros:\n",
        "Comprehensive Evaluation: Tests both models on both datasets, providing baseline performance (R1, R2 on A) and noisy performance (R1', R2' on B).\n",
        "Robustness Focus: The percentage drop directly measures how much noise (B) degrades performance, highlighting M1’s fusion robustness if its drop is smaller.\n",
        "Intra-Dataset Insight: Shows how well each model learns its training distribution (A or B), revealing if M1’s fusion architecture better captures clean or noisy patterns.\n",
        "Comparative Depth: Allows comparison of models’ generalization within and across datasets.\n",
        "- Cons:\n",
        "High Computational Cost: Requires training each model twice (on A and B), doubling the training time compared to Idea 1.\n",
        "Complexity: More steps to implement and interpret, especially computing and comparing percentage drops.\n",
        "Synthetic Data Challenges: If B’s labels are random or its features are too noisy (e.g., mode collapse), training on B may lead to poor or unstable results (R1', R2'), making percentage drops hard to interpret.\n",
        "Assumes Trainability on B: Training on noisy data (B) may not be meaningful if B’s features lack structure or label coherence, reducing the validity of R1' and R2'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYRic7v1cuEn"
      },
      "source": [
        "## Best pratice test\n",
        "#### Train M1 on A, test on A (record accuracy/loss as R1) and B (record R1').\n",
        "#### Train M2 on A, test on A (record R2) and B (record R2').\n",
        "#### Compare:\n",
        "#### - R1 vs. R2 (baseline performance on clean data A).\n",
        "#### - R1' vs. R2' (robustness to noisy data B).\n",
        "#### - Percentage drop: (R1 - R1') / R1 vs. (R2 - R2') / R2 (quantify robustness).\n",
        "#### - Visualize all metrics (R1, R2, R1', R2', and drops) in a bar plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCzHxQbQdxbG"
      },
      "source": [
        "### Test on fushion model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E4gweACbXEe9",
        "outputId": "91585579-3d92-404c-fba4-010b61a52913"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-09 22:11:12.292126: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-09 22:11:12.298890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749481872.305546   23365 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749481872.307478   23365 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749481872.313700   23365 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749481872.313711   23365 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749481872.313712   23365 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749481872.313713   23365 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-09 22:11:12.316087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./dataset/fusion_with_vector_extended.csv: Removed 3 rows with invalid labels.\n",
            "Loaded original dataset (A)\n",
            "Loaded synthetic dataset (B)\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-09 22:11:14.338903: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.4072 - loss: 6.3542 - val_accuracy: 0.2000 - val_loss: 16.3598\n",
            "Epoch 2/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.6901 - loss: 3.2588 - val_accuracy: 0.4625 - val_loss: 8.8125\n",
            "Epoch 3/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.6878 - loss: 2.4359 - val_accuracy: 0.6104 - val_loss: 5.4899\n",
            "Epoch 4/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.8069 - loss: 1.7732 - val_accuracy: 0.9322 - val_loss: 1.3019\n",
            "Epoch 5/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.8625 - loss: 1.4077 - val_accuracy: 0.8502 - val_loss: 1.4490\n",
            "Epoch 6/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.7674 - loss: 1.5784 - val_accuracy: 0.8580 - val_loss: 1.1421\n",
            "Epoch 7/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.8323 - loss: 1.2169 - val_accuracy: 0.9316 - val_loss: 0.9158\n",
            "Epoch 8/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9052 - loss: 0.9105 - val_accuracy: 0.9205 - val_loss: 0.8301\n",
            "Epoch 9/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.9032 - loss: 0.8671 - val_accuracy: 0.9322 - val_loss: 0.7456\n",
            "Epoch 10/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.9205 - loss: 0.7071 - val_accuracy: 0.7329 - val_loss: 0.9919\n",
            "Epoch 11/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.9177 - loss: 0.6729 - val_accuracy: 0.9427 - val_loss: 0.6013\n",
            "Epoch 12/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.8636 - loss: 0.9559 - val_accuracy: 0.8033 - val_loss: 0.9384\n",
            "Epoch 13/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.9272 - loss: 0.7994 - val_accuracy: 0.9329 - val_loss: 0.5925\n",
            "Epoch 14/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9022 - loss: 0.6473 - val_accuracy: 0.8430 - val_loss: 0.7307\n",
            "Epoch 15/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.9149 - loss: 0.6225 - val_accuracy: 0.9368 - val_loss: 0.5284\n",
            "Epoch 16/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9276 - loss: 0.5418 - val_accuracy: 0.9010 - val_loss: 0.5718\n",
            "Epoch 17/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.9348 - loss: 0.4862 - val_accuracy: 0.9277 - val_loss: 0.4491\n",
            "Epoch 18/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.9473 - loss: 0.4034 - val_accuracy: 0.9420 - val_loss: 0.4127\n",
            "Epoch 19/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.9485 - loss: 0.3940 - val_accuracy: 0.8827 - val_loss: 0.5597\n",
            "Epoch 20/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 93ms/step - accuracy: 0.9389 - loss: 0.4285 - val_accuracy: 0.9518 - val_loss: 0.3370\n",
            "Epoch 21/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 102ms/step - accuracy: 0.9531 - loss: 0.3645 - val_accuracy: 0.8717 - val_loss: 0.5128\n",
            "Epoch 22/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.9334 - loss: 0.4311 - val_accuracy: 0.7935 - val_loss: 0.9014\n",
            "Epoch 23/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.9273 - loss: 0.4736 - val_accuracy: 0.8580 - val_loss: 0.5629\n",
            "Epoch 24/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.9516 - loss: 0.3580 - val_accuracy: 0.9375 - val_loss: 0.3667\n",
            "Epoch 25/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 86ms/step - accuracy: 0.9398 - loss: 0.3999 - val_accuracy: 0.9420 - val_loss: 0.3637\n",
            "M1 (Fusion Model) on Dataset A: Test Accuracy: 0.9518, Test Loss: 0.3370\n",
            "M1 (Fusion Model) on Dataset B: Test Accuracy: 0.2030, Test Loss: 4.1839\n",
            "Epoch 1/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7669 - loss: 2.7950 - val_accuracy: 0.8945 - val_loss: 1.7793\n",
            "Epoch 2/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 1.6595 - val_accuracy: 0.8964 - val_loss: 1.1608\n",
            "Epoch 3/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 1.1067 - val_accuracy: 0.8990 - val_loss: 0.8282\n",
            "Epoch 4/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.7851 - val_accuracy: 0.8951 - val_loss: 0.6070\n",
            "Epoch 5/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.5759 - val_accuracy: 0.8951 - val_loss: 0.4937\n",
            "Epoch 6/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.4867 - val_accuracy: 0.8958 - val_loss: 0.4527\n",
            "Epoch 7/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.4431 - val_accuracy: 0.9094 - val_loss: 0.3860\n",
            "Epoch 8/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.4087 - val_accuracy: 0.9173 - val_loss: 0.3750\n",
            "Epoch 9/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3996 - val_accuracy: 0.8971 - val_loss: 0.3612\n",
            "Epoch 10/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.3588 - val_accuracy: 0.9303 - val_loss: 0.3475\n",
            "Epoch 11/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.3847 - val_accuracy: 0.9401 - val_loss: 0.3306\n",
            "Epoch 12/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.3555 - val_accuracy: 0.9231 - val_loss: 0.3531\n",
            "Epoch 13/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.3581 - val_accuracy: 0.9336 - val_loss: 0.3564\n",
            "Epoch 14/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.3763 - val_accuracy: 0.9336 - val_loss: 0.3230\n",
            "Epoch 15/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.3929 - val_accuracy: 0.9264 - val_loss: 0.3286\n",
            "Epoch 16/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.3492 - val_accuracy: 0.9316 - val_loss: 0.3332\n",
            "Epoch 17/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.3590 - val_accuracy: 0.9251 - val_loss: 0.3558\n",
            "Epoch 18/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.3814 - val_accuracy: 0.9329 - val_loss: 0.3139\n",
            "Epoch 19/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.3501 - val_accuracy: 0.9322 - val_loss: 0.3306\n",
            "Epoch 20/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.3964 - val_accuracy: 0.9290 - val_loss: 0.3174\n",
            "Epoch 21/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.3511 - val_accuracy: 0.9296 - val_loss: 0.3395\n",
            "Epoch 22/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.3394 - val_accuracy: 0.9088 - val_loss: 0.3525\n",
            "Epoch 23/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.3512 - val_accuracy: 0.9427 - val_loss: 0.2991\n",
            "Epoch 24/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.3589 - val_accuracy: 0.9316 - val_loss: 0.3124\n",
            "Epoch 25/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.3287 - val_accuracy: 0.9362 - val_loss: 0.3050\n",
            "Epoch 26/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.3386 - val_accuracy: 0.9375 - val_loss: 0.3079\n",
            "Epoch 27/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.3415 - val_accuracy: 0.9336 - val_loss: 0.3148\n",
            "Epoch 28/50\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.3228 - val_accuracy: 0.9414 - val_loss: 0.3274\n",
            "M2 (Mono Model) on Dataset A: Test Accuracy: 0.9427, Test Loss: 0.2991\n",
            "M2 (Mono Model) on Dataset B: Test Accuracy: 0.1964, Test Loss: 3.5169\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison plot saved as 'model_comparison.png'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, feature_dim=512):\n",
        "    data = pd.read_csv(csv_path)\n",
        "    valid_labels = {'Bypass', 'Downloader', 'Injector', 'Payload', 'TaskExecution'}\n",
        "    original_rows = len(data)\n",
        "    data = data[data['Label'].isin(valid_labels)]\n",
        "    removed_rows = original_rows - len(data)\n",
        "    if removed_rows > 0:\n",
        "        print(f\"{csv_path}: Removed {removed_rows} rows with invalid labels.\")\n",
        "    if data.empty:\n",
        "        raise ValueError(f\"{csv_path}: No rows remain after filtering.\")\n",
        "\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "    assert features.shape[1] == feature_dim, f\"{csv_path}: Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "    features = features.reshape(-1, feature_dim, 1)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(data['Label'])\n",
        "    labels = tf.keras.utils.to_categorical(labels, num_classes=5)\n",
        "\n",
        "    return features, labels, scaler, label_encoder\n",
        "\n",
        "# M1: Fusion Model (CNN+BiLSTM+Transformer)\n",
        "def create_fusion_model(input_shape=(512, 1), num_classes=5):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.005))(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Conv1D(filters=128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.005))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.005)))(x)\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.005)))(x)\n",
        "    transformer = MultiHeadAttention(num_heads=8, key_dim=64)\n",
        "    x = transformer(x, x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.005))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# M2: Mono Model (MLP)\n",
        "def create_mono_model(input_shape=(512, 1), num_classes=5):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Flatten()(input_layer)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.005))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.005))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train and evaluate model\n",
        "def train_and_evaluate(model, features_a, labels_a, features_b, labels_b, model_name, test_size=0.2, epochs=50, batch_size=32):\n",
        "    # Split Dataset A\n",
        "    try:\n",
        "        X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(\n",
        "            features_a, labels_a, test_size=test_size, stratify=labels_a.argmax(axis=1), random_state=42\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"{model_name} on Dataset A: Error in train_test_split: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # Train on A\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train_a, y_train_a,\n",
        "        validation_data=(X_test_a, y_test_a),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Test on A\n",
        "    loss_a, accuracy_a = model.evaluate(X_test_a, y_test_a, verbose=0)\n",
        "    print(f\"{model_name} on Dataset A: Test Accuracy: {accuracy_a:.4f}, Test Loss: {loss_a:.4f}\")\n",
        "\n",
        "    # Test on B\n",
        "    loss_b, accuracy_b = model.evaluate(features_b, labels_b, verbose=0)\n",
        "    print(f\"{model_name} on Dataset B: Test Accuracy: {accuracy_b:.4f}, Test Loss: {loss_b:.4f}\")\n",
        "\n",
        "    # Compute percentage drop\n",
        "    accuracy_drop = (accuracy_a - accuracy_b) / accuracy_a * 100 if accuracy_a > 0 else 0\n",
        "\n",
        "    return accuracy_a, loss_a, accuracy_b, loss_b, accuracy_drop\n",
        "\n",
        "# Visualize results\n",
        "def visualize_comparison(results):\n",
        "    models = ['M1 (Fusion)', 'M2 (Mono)']\n",
        "    accuracies_a = [results['M1']['accuracy_a'], results['M2']['accuracy_a']]\n",
        "    accuracies_b = [results['M1']['accuracy_b'], results['M2']['accuracy_b']]\n",
        "    losses_a = [results['M1']['loss_a'], results['M2']['loss_a']]\n",
        "    losses_b = [results['M1']['loss_b'], results['M2']['loss_b']]\n",
        "    drops = [results['M1']['drop'], results['M2']['drop']]\n",
        "\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.15\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Plot accuracies and losses\n",
        "    ax1.bar(x - width*1.5, accuracies_a, width, label='Accuracy A', color='skyblue')\n",
        "    ax1.bar(x - width/2, accuracies_b, width, label='Accuracy B', color='lightgreen')\n",
        "    ax1.bar(x + width/2, losses_a, width, label='Loss A', color='salmon')\n",
        "    ax1.bar(x + width*1.5, losses_b, width, label='Loss B', color='coral')\n",
        "\n",
        "    ax1.set_xlabel('Model')\n",
        "    ax1.set_title('Performance on Original (A) vs Synthetic (B)')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(models)\n",
        "    ax1.legend()\n",
        "\n",
        "    # Add value labels\n",
        "    for i, v in enumerate(accuracies_a):\n",
        "        ax1.text(i - width*1.5, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "    for i, v in enumerate(accuracies_b):\n",
        "        ax1.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "    for i, v in enumerate(losses_a):\n",
        "        ax1.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "    for i, v in enumerate(losses_b):\n",
        "        ax1.text(i + width*1.5, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "    # Plot accuracy drops\n",
        "    ax2.bar(x, drops, width, label='Accuracy Drop (%)', color='purple')\n",
        "    ax2.set_xlabel('Model')\n",
        "    ax2.set_title('Accuracy Drop from A to B')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(models)\n",
        "    ax2.legend()\n",
        "\n",
        "    for i, v in enumerate(drops):\n",
        "        ax2.text(i, v + 1, f\"{v:.1f}%\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"model_comparison.png\")\n",
        "    plt.show()\n",
        "    print(\"Comparison plot saved as 'model_comparison.png'\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to datasets\n",
        "    original_csv = \"./dataset/fusion_with_vector_extended.csv\"\n",
        "    synthetic_csv = \"./GAN/synthetic_powershell_malware.csv\"\n",
        "\n",
        "    # Load datasets\n",
        "    try:\n",
        "        features_a, labels_a, scaler_a, encoder_a = load_and_preprocess_data(original_csv)\n",
        "        print(\"Loaded original dataset (A)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading original dataset: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        features_b, labels_b, scaler_b, encoder_b = load_and_preprocess_data(synthetic_csv)\n",
        "        print(\"Loaded synthetic dataset (B)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading synthetic dataset: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Evaluate models\n",
        "    results = {'M1': {}, 'M2': {}}\n",
        "\n",
        "    # M1: Fusion Model\n",
        "    m1 = create_fusion_model()\n",
        "    result_m1 = train_and_evaluate(m1, features_a, labels_a, features_b, labels_b, \"M1 (Fusion Model)\")\n",
        "    if result_m1[0] is not None:\n",
        "        results['M1']['accuracy_a'], results['M1']['loss_a'], results['M1']['accuracy_b'], results['M1']['loss_b'], results['M1']['drop'] = result_m1\n",
        "    else:\n",
        "        print(\"Failed to evaluate M1. Check dataset size or labels.\")\n",
        "        exit(1)\n",
        "\n",
        "    # M2: Mono Model\n",
        "    m2 = create_mono_model()\n",
        "    result_m2 = train_and_evaluate(m2, features_a, labels_a, features_b, labels_b, \"M2 (Mono Model)\")\n",
        "    if result_m2[0] is not None:\n",
        "        results['M2']['accuracy_a'], results['M2']['loss_a'], results['M2']['accuracy_b'], results['M2']['loss_b'], results['M2']['drop'] = result_m2\n",
        "    else:\n",
        "        print(\"Failed to evaluate M2. Check dataset size or labels.\")\n",
        "        exit(1)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_comparison(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOIKTvmChH5ngAtN9MH+6GK",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
